

Operator APIs
================
The following documentations are automatically extracted from the corresponding original backend libraries.




----

beacon_aug.Affine:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Augmentation to apply affine transformations to images.
    This is mostly a wrapper around the corresponding classes and functions in OpenCV.

    Affine transformations involve:

        - Translation ("move" image on the x-/y-axis)
        - Rotation
        - Scaling ("zoom" in/out)
        - Shear (move one side of the image, turning a square into a trapezoid)

    All such transformations can create "new" pixels in the image without a defined content, e.g.
    if the image is translated to the left, pixels are created on the right.
    A method has to be defined to deal with these pixel values.
    The parameters `cval` and `mode` of this class deal with this.

    Some transformations involve interpolations between several pixels
    of the input image to generate output pixel values. The parameter `order`
    deals with the method of interpolation used for this.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``keras`` , ``torchvision`` .
								Default: `` albumentations``.
        scale (number, tuple of number or dict): Scaling factor to use, where ``1.0`` denotes "no change" and
            ``0.5`` is zoomed out to ``50`` percent of the original size.
                * If a single number, then that value will be used for all images.
                * If a tuple ``(a, b)``, then a value will be uniformly sampled per image from the interval ``[a, b]``.
                  That value will be used identically for both x- and y-axis.
                * If a dictionary, then it is expected to have the keys ``x`` and/or ``y``.
                  Each of these keys can have the same values as described above.
                  Using a dictionary allows to set different values for the two axis and sampling will then happen
                  *independently* per axis, resulting in samples that differ between the axes.
        translate_percent (None, number, tuple of number or dict): Translation as a fraction of the image height/width
            (x-translation, y-translation), where ``0`` denotes "no change"
            and ``0.5`` denotes "half of the axis size".
                * If ``None`` then equivalent to ``0.0`` unless `translate_px` has a value other than ``None``.
                * If a single number, then that value will be used for all images.
                * If a tuple ``(a, b)``, then a value will be uniformly sampled per image from the interval ``[a, b]``.
                  That sampled fraction value will be used identically for both x- and y-axis.
                * If a dictionary, then it is expected to have the keys ``x`` and/or ``y``.
                  Each of these keys can have the same values as described above.
                  Using a dictionary allows to set different values for the two axis and sampling will then happen
                  *independently* per axis, resulting in samples that differ between the axes.
        translate_px (None, int, tuple of int or dict): Translation in pixels.
                * If ``None`` then equivalent to ``0`` unless `translate_percent` has a value other than ``None``.
                * If a single int, then that value will be used for all images.
                * If a tuple ``(a, b)``, then a value will be uniformly sampled per image from
                  the discrete interval ``[a..b]``. That number will be used identically for both x- and y-axis.
                * If a dictionary, then it is expected to have the keys ``x`` and/or ``y``.
                  Each of these keys can have the same values as described above.
                  Using a dictionary allows to set different values for the two axis and sampling will then happen
                  *independently* per axis, resulting in samples that differ between the axes.
        rotate (number or tuple of number): Rotation in degrees (**NOT** radians), i.e. expected value range is
            around ``[-360, 360]``. Rotation happens around the *center* of the image,
            not the top left corner as in some other frameworks.
                * If a number, then that value will be used for all images.
                * If a tuple ``(a, b)``, then a value will be uniformly sampled per image from the interval ``[a, b]``
                  and used as the rotation value.
        shear (number, tuple of number or dict): Shear in degrees (**NOT** radians), i.e. expected value range is
            around ``[-360, 360]``, with reasonable values being in the range of ``[-45, 45]``.
                * If a number, then that value will be used for all images as
                  the shear on the x-axis (no shear on the y-axis will be done).
                * If a tuple ``(a, b)``, then two value will be uniformly sampled per image
                  from the interval ``[a, b]`` and be used as the x- and y-shear value.
                * If a dictionary, then it is expected to have the keys ``x`` and/or ``y``.
                  Each of these keys can have the same values as described above.
                  Using a dictionary allows to set different values for the two axis and sampling will then happen
                  *independently* per axis, resulting in samples that differ between the axes.
        interpolation (int): OpenCV interpolation flag.
        mask_interpolation (int): OpenCV interpolation flag.
        cval (number or sequence of number): The constant value to use when filling in newly created pixels.
            (E.g. translating by 1px to the right will create a new 1px-wide column of pixels
            on the left of the image).
            The value is only used when `mode=constant`. The expected value range is ``[0, 255]`` for ``uint8`` images.
        cval_mask (number or tuple of number): Same as cval but only for masks.
        mode (int): OpenCV border flag.
        fit_output (bool): Whether to modify the affine transformation so that the whole output image is always
            contained in the image plane (``True``) or accept parts of the image being outside
            the image plane (``False``). This can be thought of as first applying the affine transformation
            and then applying a second transformation to "zoom in" on the new image so that it fits the image plane,
            This is useful to avoid corners of the image being outside of the image plane after applying rotations.
            It will however negate translation and scaling.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Affine``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.Affine>`_ 

            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter or dict {"x": number/tuple/list/StochasticParameter, "y": number/tuple/list/StochasticParameter}, optional):
                Scaling factor to use, where ``1.0`` denotes "no change" and
                ``0.5`` is zoomed out to ``50`` percent of the original size.


            translate_percent( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter or dict {"x": number/tuple/list/StochasticParameter, "y": number/tuple/list/StochasticParameter}, optional):
                Translation as a fraction of the image height/width (x-translation,
                y-translation), where ``0`` denotes "no change" and ``0.5`` denotes
                "half of the axis size".


            translate_px( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter or dict {"x": int/tuple/list/StochasticParameter, "y": int/tuple/list/StochasticParameter}, optional):
                Translation in pixels.


            rotate( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Rotation in degrees (**NOT** radians), i.e. expected value range is
                around ``[-360, 360]``. Rotation happens around the *center* of the
                image, not the top left corner as in some other frameworks.


            shear( number or tuple of number or list of number or imgaug.parameters.StochasticParameter or dict {"x": int/tuple/list/StochasticParameter, "y": int/tuple/list/StochasticParameter}, optional):
                Shear in degrees (**NOT** radians), i.e. expected value range is
                around ``[-360, 360]``, with reasonable values being in the range
                of ``[-45, 45]``.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.


        if library = ``torchvision``:       (see: ``RandomAffine)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomAffine>`_ 
    
            degrees (sequence or number): Range of degrees to select from.
                If degrees is a number instead of sequence like (min, max), the range of degrees
                will be (-degrees, +degrees). Set to 0 to deactivate rotations.
            translate (tuple, optional): tuple of maximum absolute fraction for horizontal
                and vertical translations. For example translate=(a, b), then horizontal shift
                is randomly sampled in the range -img_width * a < dx < img_width * a and vertical shift is
                randomly sampled in the range -img_height * b < dy < img_height * b. Will not translate by default.
            scale (tuple, optional): scaling factor interval, e.g (a, b), then scale is
                randomly sampled from the range a <= scale <= b. Will keep original scale by default.
            shear (sequence or number, optional): Range of degrees to select from.
                If shear is a number, a shear parallel to the x axis in the range (-shear, +shear)
                will be applied. Else if shear is a sequence of 2 values a shear parallel to the x axis in the
                range (shear[0], shear[1]) will be applied. Else if shear is a sequence of 4 values,
                a x-axis shear in (shear[0], shear[1]) and y-axis shear in (shear[2], shear[3]) will be applied.
                Will not apply shear by default.
            interpolation (InterpolationMode): Desired interpolation enum defined by
                :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.
                If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
                For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.
            fill (sequence or number): Pixel fill value for the area outside the transformed
                image. Default is ``0``. If given a number, the value is used for all bands respectively.
            fillcolor (sequence or number, optional): deprecated argument and will be removed since v0.10.0.
                Please use the ``fill`` parameter instead.
            resample (int, optional): deprecated argument and will be removed since v0.10.0.
                Please use the ``interpolation`` parameter instead.

    if library = ``keras``:       (see: ``apply_affine_transform``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform>`_
    
            x: 2D numpy array, single image.
            theta: Rotation angle in degrees.
            tx: Width shift.
            ty: Heigh shift.
            shear: Shear angle in degrees.
            zx: Zoom in x direction.
            zy: Zoom in y direction
            row_axis: Index of axis for rows in the input image.
            col_axis: Index of axis for columns in the input image.
            channel_axis: Index of axis for channels in the input image.
            fill_mode: Points outside the boundaries of the input
                are filled according to the given mode
                (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).
            cval: Value used for points outside the boundaries
                of the input if `mode='constant'`.
            order: int, order of interpolation
    
        


    Targets:
        image, mask, keypoints, bboxes

    Image types:
        uint8, float32

    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Affine(p=1,  library="albumentations")
        aug = BA.Affine(p=1,  library="imgaug")
        aug = BA.Affine(p=1,  library="torchvision")
        aug = BA.Affine(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PiecewiseAffine:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Apply affine transformations that differ between local neighbourhoods.
    This augmentation places a regular grid of points on an image and randomly moves the neighbourhood of these point
    around via affine transformations. This leads to local distortions.

    This is mostly a wrapper around scikit-image's ``PiecewiseAffine``.
    See also ``Affine`` for a similar technique.

    Note:
        This augmenter is very slow. Try to use ``ElasticTransformation`` instead, which is at least 10x faster.

    Note:
        For coordinate-based inputs (keypoints, bounding boxes, polygons, ...),
        this augmenter still has to perform an image-based augmentation,
        which will make it significantly slower and not fully correct for such inputs than other transforms.

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``albumentations`` .
								Default: `` albumentations``.
        scale (float, tuple of float): Each point on the regular grid is moved around via a normal distribution.
            This scale factor is equivalent to the normal distribution's sigma.
            Note that the jitter (how far each point is moved in which direction) is multiplied by the height/width of
            the image if ``absolute_scale=False`` (default), so this scale can be the same for different sized images.
            Recommended values are in the range ``0.01`` to ``0.05`` (weak to strong augmentations).
                * If a single ``float``, then that value will always be used as the scale.
                * If a tuple ``(a, b)`` of ``float`` s, then a random value will
                  be uniformly sampled per image from the interval ``[a, b]``.
        nb_rows (int, tuple of int): Number of rows of points that the regular grid should have.
            Must be at least ``2``. For large images, you might want to pick a higher value than ``4``.
            You might have to then adjust scale to lower values.
                * If a single ``int``, then that value will always be used as the number of rows.
                * If a tuple ``(a, b)``, then a value from the discrete interval
                  ``[a..b]`` will be uniformly sampled per image.
        nb_cols (int, tuple of int): Number of columns. Analogous to `nb_rows`.
        interpolation (int): The order of interpolation. The order has to be in the range 0-5:
             - 0: Nearest-neighbor
             - 1: Bi-linear (default)
             - 2: Bi-quadratic
             - 3: Bi-cubic
             - 4: Bi-quartic
             - 5: Bi-quintic
        mask_interpolation (int): same as interpolation but for mask.
        cval (number): The constant value to use when filling in newly created pixels.
        cval_mask (number): Same as cval but only for masks.
        mode (str): {'constant', 'edge', 'symmetric', 'reflect', 'wrap'}, optional
            Points outside the boundaries of the input are filled according
            to the given mode.  Modes match the behaviour of `numpy.pad`.
        absolute_scale (bool): Take `scale` as an absolute value rather than a relative value.
        keypoints_threshold (float): Used as threshold in conversion from distance maps to keypoints.
            The search for keypoints works by searching for the
            argmin (non-inverted) or argmax (inverted) in each channel. This
            parameters contains the maximum (non-inverted) or minimum (inverted) value to accept in order to view a hit
            as a keypoint. Use ``None`` to use no min/max. Default: 0.01

        if library = ``imgaug``:       (see: ``PiecewiseAffine``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.PiecewiseAffine>`_ 

            scale( float or tuple of float or imgaug.parameters.StochasticParameter, optional):
                Each point on the regular grid is moved around via a normal
                distribution. This scale factor is equivalent to the normal
                distribution's sigma. Note that the jitter (how far each point is
                moved in which direction) is multiplied by the height/width of the
                image if ``absolute_scale=False`` (default), so this scale can be
                the same for different sized images.
                Recommended values are in the range ``0.01`` to ``0.05`` (weak to
                strong augmentations).


            nb_rows( int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                Number of rows of points that the regular grid should have.
                Must be at least ``2``. For large images, you might want to pick a
                higher value than ``4``. You might have to then adjust scale to lower
                values.


            nb_cols( int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                Number of columns. Analogous to `nb_rows`.


            order( int or list of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.geometric.Affine.__init__`.


            cval( int or float or tuple of float or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.geometric.Affine.__init__`.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.geometric.Affine.__init__`.


            absolute_scale( bool, optional):
                Take `scale` as an absolute value rather than a relative value.


            polygon_recoverer( 'auto' or None or imgaug.augmentables.polygons._ConcavePolygonRecoverer, optional):
                The class to use to repair invalid polygons.
                If ``"auto"``, a new instance of
                :class`imgaug.augmentables.polygons._ConcavePolygonRecoverer`
                will be created.
                If ``None``, no polygon recoverer will be used.
                If an object, then that object will be used and must provide a
                ``recover_from()`` method, similar to
                :class:`~imgaug.augmentables.polygons._ConcavePolygonRecoverer`.


    Targets:
        image, mask, keypoints, bboxes

    Image types:
        uint8, float32

    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PiecewiseAffine(p=1,  library="albumentations")
        aug = BA.PiecewiseAffine(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Cutout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

CoarseDropout of the square regions in the image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        num_holes (int): number of regions to zero out
        max_h_size (int): maximum height of the hole
        max_w_size (int): maximum width of the hole
        fill_value (int, float, list of int, list of float): value for dropped pixels.

        if library = ``imgaug``:       (see: ``Cutout``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Cutout>`_ 

            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                Defines the position of each area to fill.
                Analogous to the definition in e.g.
                :class:`~imgaug.augmenters.size.CropToFixedSize`.
                Usually, ``uniform`` (anywhere in the image) or ``normal`` (anywhere
                in the image with preference around the center) are sane values.


            size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The size of the rectangle to fill as a fraction of the corresponding
                image size, i.e. with value range ``[0.0, 1.0]``. The size is sampled
                independently per image axis.


            squared( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to generate only squared areas cutout areas or allow
                rectangular ones. If this evaluates to a true-like value, the
                first value from `size` will be converted to absolute pixels and used
                for both axes.


            fill_mode( str or list of str or imgaug.parameters.StochasticParameter, optional):
                Mode to use in order to fill areas. Corresponds to ``mode`` parameter
                in some other augmenters. Valid strings for the mode are:


            cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The value to use (i.e. the color) to fill areas if `fill_mode` is
                ```constant``.


            fill_per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to fill each area in a channelwise fashion (``True``) or
                not (``False``).
                The behaviour per fill mode is:


        if library = ``torchvision``:       (see: ``RandomErasing)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomErasing>`_ 
    
             p: probability that the random erasing operation will be performed.
             scale: range of proportion of erased area against input image.
             ratio: range of aspect ratio of erased area.
             value: erasing value. Default is 0. If a single int, it is used to
                erase all pixels. If a tuple of length 3, it is used to erase
                R, G, B channels respectively.
                If a str of 'random', erasing each pixel with random values.
             inplace: boolean to make this transform inplace. Default set to False.

    Targets:
        image

    Image types:
        uint8, float32

    Reference:
    |  https://arxiv.org/abs/1708.04552
    |  https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py
    |  https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Cutout(p=1, num_holes=8, library="albumentations")
        aug = BA.Cutout(p=1, num_holes=8, library="imgaug")
        aug = BA.Cutout(p=1, num_holes=8, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Crop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Crop``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.Crop>`_ 

            px( None or int or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to crop on each side of the image.
                Expected value range is ``[0, inf)``.
                Either this or the parameter `percent` may be set, not both at the same
                time.


            percent( None or int or float or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to crop
                on each side of the image given as a *fraction* of the image
                height/width. E.g. if this is set to ``0.1``, the augmenter will
                always crop ``10%`` of the image's height at both the top and the
                bottom (both ``10%`` each), as well as ``10%`` of the width at the
                right and left.
                Expected value range is ``[0.0, 1.0)``.
                Either this or the parameter `px` may be set, not both
                at the same time.


            keep_size( bool, optional):
                After cropping, the result image will usually have a
                different height/width compared to the original input image. If this
                parameter is set to ``True``, then the cropped image will be
                resized to the input image's size, i.e. the augmenter's output shape
                is always identical to the input shape.


            sample_independently( bool, optional):
                If ``False`` *and* the values for `px`/`percent` result in exactly
                *one* probability distribution for all image sides, only one single
                value will be sampled from that probability distribution and used for
                all sides. I.e. the crop amount then is the same for all sides.
                If ``True``, four values will be sampled independently, one per side.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Crop(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop a random part of the input.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        height (int): height of the crop.
        width (int): width of the crop.
        p (float): probability of applying the transform. Default: 1.

        if library = ``imgaug``:       (see: ``CropToFixedSize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToFixedSize>`_ 

            width( int or None):
                Crop images down to this maximum width.
                If ``None``, image widths will not be altered.


            height( int or None):
                Crop images down to this maximum height.
                If ``None``, image heights will not be altered.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                 Sets the center point of the cropping, which determines how the
                 required cropping amounts are distributed to each side. For a
                 ``tuple`` ``(a, b)``, both ``a`` and ``b`` are expected to be in
                 range ``[0.0, 1.0]`` and describe the fraction of cropping applied
                 to the left/right (low/high values for ``a``) and the fraction
                 of cropping applied to the top/bottom (low/high values for ``b``).
                 A cropping position at ``(0.5, 0.5)`` would be the center of the
                 image and distribute the cropping equally over all sides. A cropping
                 position at ``(1.0, 0.0)`` would be the right-top and would apply
                 100% of the required cropping to the right and top sides of the image.


        if library = ``torchvision``:       (see: ``RandomCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomCrop>`_ 
    
            size (sequence or int): Desired output size of the crop. If size is an
                int instead of sequence like (h, w), a square crop (size, size) is
                made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).
            padding (int or sequence, optional): Optional padding on each border
                of the image. Default is None. If a single int is provided this
                is used to pad all borders. If sequence of length 2 is provided this is the padding
                on left/right and top/bottom respectively. If a sequence of length 4 is provided
                this is the padding for the left, top, right and bottom borders respectively.

    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomCrop(p=1, height=64,width=64, library="albumentations")
        aug = BA.RandomCrop(p=1, height=64,width=64, library="imgaug")
        aug = BA.RandomCrop(p=1, height=64,width=64, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop the central part of the input.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``torchvision`` .
								Default: `` albumentations``.
        height (int): height of the crop.
        width (int): width of the crop.
        p (float): probability of applying the transform. Default: 1.

            if library = ``torchvision``:       (see: ``CenterCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#CenterCrop>`_ 
    
            size (sequence or int): Desired output size of the crop. If size is an
                int instead of sequence like (h, w), a square crop (size, size) is
                made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).
        


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32

    Note:
        It is recommended to use uint8 images as input.
        Otherwise the operation will require internal conversion
        float32 -> uint8 -> float32 that causes worse performance.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCrop(p=1, height=64,width=64, library="albumentations")
        aug = BA.CenterCrop(p=1, height=64,width=64, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomSizedCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop a random part of the input and rescale it to some size.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``torchvision`` .
								Default: `` albumentations``.
        min_max_height ((int, int)): crop size limits.
        height (int): height after crop and resize.
        width (int): width after crop and resize.
        w2h_ratio (float): aspect ratio of crop.
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

            if library = ``torchvision``:       (see: ``RandomResizedCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomResizedCrop>`_ 
    
            size (int or sequence): expected output size of the crop, for each edge. If size is an
                int instead of sequence like (h, w), a square output size ``(size, size)`` is
                made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).

    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomSizedCrop(p=1, height=64,width=64, library="albumentations")
        aug = BA.RandomSizedCrop(p=1, height=64,width=64, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomResizedCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Torchvision's variant of crop a random part of the input and rescale it to some size.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``torchvision`` .
								Default: `` albumentations``.
        height (int): height after crop and resize.
        width (int): width after crop and resize.
        scale ((float, float)): range of size of the origin size cropped
        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

            if library = ``torchvision``:       (see: ``RandomResizedCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomResizedCrop>`_ 
    
            size (int or sequence): expected output size of the crop, for each edge. If size is an
                int instead of sequence like (h, w), a square output size ``(size, size)`` is
                made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).

    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomResizedCrop(p=1,  library="albumentations")
        aug = BA.RandomResizedCrop(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Resize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Resize the input to the given height and width.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        height (int): desired height of the output.
        width (int): desired width of the output.
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

        if library = ``imgaug``:       (see: ``Resize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.Resize>`_ 

            size( 'keep' or int or float or tuple of int or tuple of float or list of int or list of float or imgaug.parameters.StochasticParameter or dict):
                The new size of the images.


            interpolation( imgaug.ALL or int or str or list of int or list of str or imgaug.parameters.StochasticParameter, optional):
                Interpolation to use.


        if library = ``torchvision``:       (see: ``Resize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Resize>`_ 
    
            size (sequence or int): Desired output size. If size is a sequence like
                (h, w), output size will be matched to this. If size is an int,
                smaller edge of the image will be matched to this number.
                i.e, if height > width, then image will be rescaled to
                (size * height / width, size).

    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Resize(p=1, height=64,width=64,interpolation=cv2.INTER_AREA, library="albumentations")
        aug = BA.Resize(p=1, height=64,width=64,interpolation=cv2.INTER_AREA, library="imgaug")
        aug = BA.Resize(p=1, height=64,width=64,interpolation=cv2.INTER_AREA, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropAndPad:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop and pad images by pixel amounts or fractions of image sizes.
    Cropping removes pixels at the sides (i.e. extracts a subimage from a given full image).
    Padding adds pixels to the sides (e.g. black pixels).
    This transformation will never crop images below a height or width of ``1``.

    Note:
        This transformation automatically resizes images back to their original size. To deactivate this, add the
        parameter ``keep_size=False``.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        px (int or tuple):
            The number of pixels to crop (negative values) or pad (positive values)
            on each side of the image. Either this or the parameter `percent` may
            be set, not both at the same time.
                * If ``None``, then pixel-based cropping/padding will not be used.
                * If ``int``, then that exact number of pixels will always be cropped/padded.
                * If a ``tuple`` of two ``int`` s with values ``a`` and ``b``,
                  then each side will be cropped/padded by a random amount sampled
                  uniformly per image and side from the interval ``[a, b]``. If
                  however `sample_independently` is set to ``False``, only one
                  value will be sampled per image and used for all sides.
                * If a ``tuple`` of four entries, then the entries represent top,
                  right, bottom, left. Each entry may be a single ``int`` (always
                  crop/pad by exactly that value), a ``tuple`` of two ``int`` s
                  ``a`` and ``b`` (crop/pad by an amount within ``[a, b]``), a
                  ``list`` of ``int`` s (crop/pad by a random value that is
                  contained in the ``list``).
        percent (float or tuple):
            The number of pixels to crop (negative values) or pad (positive values)
            on each side of the image given as a *fraction* of the image
            height/width. E.g. if this is set to ``-0.1``, the transformation will
            always crop away ``10%`` of the image's height at both the top and the
            bottom (both ``10%`` each), as well as ``10%`` of the width at the
            right and left.
            Expected value range is ``(-1.0, inf)``.
            Either this or the parameter `px` may be set, not both
            at the same time.
                * If ``None``, then fraction-based cropping/padding will not be
                  used.
                * If ``float``, then that fraction will always be cropped/padded.
                * If a ``tuple`` of two ``float`` s with values ``a`` and ``b``,
                  then each side will be cropped/padded by a random fraction
                  sampled uniformly per image and side from the interval
                  ``[a, b]``. If however `sample_independently` is set to
                  ``False``, only one value will be sampled per image and used for
                  all sides.
                * If a ``tuple`` of four entries, then the entries represent top,
                  right, bottom, left. Each entry may be a single ``float``
                  (always crop/pad by exactly that percent value), a ``tuple`` of
                  two ``float`` s ``a`` and ``b`` (crop/pad by a fraction from
                  ``[a, b]``), a ``list`` of ``float`` s (crop/pad by a random
                  value that is contained in the list).
        pad_mode (int): OpenCV border mode.
        pad_cval (number, Sequence[number]):
            The constant value to use if the pad mode is ``BORDER_CONSTANT``.
                * If ``number``, then that value will be used.
                * If a ``tuple`` of two ``number`` s and at least one of them is
                  a ``float``, then a random number will be uniformly sampled per
                  image from the continuous interval ``[a, b]`` and used as the
                  value. If both ``number`` s are ``int`` s, the interval is
                  discrete.
                * If a ``list`` of ``number``, then a random value will be chosen
                  from the elements of the ``list`` and used as the value.
        pad_cval_mask (number, Sequence[number]): Same as pad_cval but only for masks.
        keep_size (bool):
            After cropping and padding, the result image will usually have a
            different height/width compared to the original input image. If this
            parameter is set to ``True``, then the cropped/padded image will be
            resized to the input image's size, i.e. the output shape is always identical to the input shape.
        sample_independently (bool):
            If ``False`` *and* the values for `px`/`percent` result in exactly
            *one* probability distribution for all image sides, only one single
            value will be sampled from that probability distribution and used for
            all sides. I.e. the crop/pad amount then is the same for all sides.
            If ``True``, four values will be sampled independently, one per side.
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.

        if library = ``imgaug``:       (see: ``CropAndPad``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropAndPad>`_ 

            px( None or int or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to crop (negative values) or pad (positive values)
                on each side of the image. Either this or the parameter `percent` may
                be set, not both at the same time.


            percent( None or number or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to crop (negative values) or pad (positive values)
                on each side of the image given as a *fraction* of the image
                height/width. E.g. if this is set to ``-0.1``, the augmenter will
                always crop away ``10%`` of the image's height at both the top and the
                bottom (both ``10%`` each), as well as ``10%`` of the width at the
                right and left.
                Expected value range is ``(-1.0, inf)``.
                Either this or the parameter `px` may be set, not both
                at the same time.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                Padding mode to use. The available modes match the numpy padding modes,
                i.e. ``constant``, ``edge``, ``linear_ramp``, ``maximum``, ``median``,
                ``minimum``, ``reflect``, ``symmetric``, ``wrap``. The modes
                ``constant`` and ``linear_ramp`` use extra values, which are provided
                by ``pad_cval`` when necessary. See :func:`~imgaug.imgaug.pad` for
                more details.


            pad_cval( number or tuple of number list of number or imgaug.parameters.StochasticParameter, optional):
                The constant value to use if the pad mode is ``constant`` or the end
                value to use if the mode is ``linear_ramp``.
                See :func:`~imgaug.imgaug.pad` for more details.


            keep_size( bool, optional):
                After cropping and padding, the result image will usually have a
                different height/width compared to the original input image. If this
                parameter is set to ``True``, then the cropped/padded image will be
                resized to the input image's size, i.e. the augmenter's output shape
                is always identical to the input shape.


            sample_independently( bool, optional):
                If ``False`` *and* the values for `px`/`percent` result in exactly
                *one* probability distribution for all image sides, only one single
                value will be sampled from that probability distribution and used for
                all sides. I.e. the crop/pad amount then is the same for all sides.
                If ``True``, four values will be sampled independently, one per side.


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        any
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropAndPad(p=1,  library="albumentations")
        aug = BA.CropAndPad(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Rotate:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Rotate the input by an angle selected randomly from the uniform distribution.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``keras`` , ``torchvision`` .
								Default: `` albumentations``.
        limit ((int, int) or int): range from which a random angle is picked. If limit is a single int
            an angle is picked from (-limit, limit). Default: (-90, 90)
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of ints,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Rotate``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.Rotate>`_ 

            rotate( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Rotation in degrees (**NOT** radians), i.e. expected value range is
                around ``[-360, 360]``. Rotation happens around the *center* of the
                image, not the top left corner as in some other frameworks.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.


        if library = ``torchvision``:       (see: ``RandomRotation)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomRotation>`_ 
    
            degrees (sequence or number): Range of degrees to select from.
                If degrees is a number instead of sequence like (min, max), the range of degrees
                will be (-degrees, +degrees).
            interpolation (InterpolationMode): Desired interpolation enum defined by
                :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.
                If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
                For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.
            expand (bool, optional): Optional expansion flag.
                If true, expands the output to make it large enough to hold the entire rotated image.
                If false or omitted, make the output image the same size as the input image.
                Note that the expand flag assumes rotation around the center and no translation.
            center (sequence, optional): Optional center of rotation, (x, y). Origin is the upper left corner.
                Default is the center of the image.
            fill (sequence or number): Pixel fill value for the area outside the rotated
                image. Default is ``0``. If given a number, the value is used for all bands respectively.
            resample (int, optional): deprecated argument and will be removed since v0.10.0.
                Please use the ``interpolation`` parameter instead.

    if library = ``keras``:       (see: ``apply_affine_transform``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_affine_transform>`_
    
            x: 2D numpy array, single image.
            theta: Rotation angle in degrees.
            tx: Width shift.
            ty: Heigh shift.
            shear: Shear angle in degrees.
            zx: Zoom in x direction.
            zy: Zoom in y direction
            row_axis: Index of axis for rows in the input image.
            col_axis: Index of axis for columns in the input image.
            channel_axis: Index of axis for channels in the input image.
            fill_mode: Points outside the boundaries of the input
                are filled according to the given mode
                (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).
            cval: Value used for points outside the boundaries
                of the input if `mode='constant'`.
            order: int, order of interpolation
    
        


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Rotate(p=1, limit=[-90, 90], library="albumentations")
        aug = BA.Rotate(p=1, limit=[-90, 90], library="imgaug")
        aug = BA.Rotate(p=1, limit=[-90, 90], library="torchvision")
        aug = BA.Rotate(p=1, limit=[-90, 90], library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Pad:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Pad``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.Pad>`_ 

            px( None or int or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to pad on each side of the image.
                Expected value range is ``[0, inf)``.
                Either this or the parameter `percent` may be set, not both at the same
                time.


            percent( None or int or float or imgaug.parameters.StochasticParameter or tuple, optional):
                The number of pixels to pad
                on each side of the image given as a *fraction* of the image
                height/width. E.g. if this is set to ``0.1``, the augmenter will
                always pad ``10%`` of the image's height at both the top and the
                bottom (both ``10%`` each), as well as ``10%`` of the width at the
                right and left.
                Expected value range is ``[0.0, inf)``.
                Either this or the parameter `px` may be set, not both
                at the same time.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                Padding mode to use. The available modes match the numpy padding modes,
                i.e. ``constant``, ``edge``, ``linear_ramp``, ``maximum``, ``median``,
                ``minimum``, ``reflect``, ``symmetric``, ``wrap``. The modes
                ``constant`` and ``linear_ramp`` use extra values, which are provided
                by ``pad_cval`` when necessary. See :func:`~imgaug.imgaug.pad` for
                more details.


            pad_cval( number or tuple of number list of number or imgaug.parameters.StochasticParameter, optional):
                The constant value to use if the pad mode is ``constant`` or the end
                value to use if the mode is ``linear_ramp``.
                See :func:`~imgaug.imgaug.pad` for more details.


            keep_size( bool, optional):
                After padding, the result image will usually have a
                different height/width compared to the original input image. If this
                parameter is set to ``True``, then the padded image will be
                resized to the input image's size, i.e. the augmenter's output shape
                is always identical to the input shape.


            sample_independently( bool, optional):
                If ``False`` *and* the values for `px`/`percent` result in exactly
                *one* probability distribution for all image sides, only one single
                value will be sampled from that probability distribution and used for
                all sides. I.e. the pad amount then is the same for all sides.
                If ``True``, four values will be sampled independently, one per side.


        if library = ``torchvision``:       (see: ``Pad)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Pad>`_ 
    
            padding (int or sequence): Padding on each border. If a single int is provided this
                is used to pad all borders. If sequence of length 2 is provided this is the padding
                on left/right and top/bottom respectively. If a sequence of length 4 is provided
                this is the padding for the left, top, right and bottom borders respectively.


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Pad(p=1,  library="imgaug")
        aug = BA.Pad(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Normalize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Normalization is applied by the formula: `img = (img - mean * max_pixel_value) / (std * max_pixel_value)`

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        mean (float, list of float): mean values
        std  (float, list of float): std values
        max_pixel_value (float): maximum possible pixel value

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Normalize(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.HorizontalFlip:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Flip the input horizontally around the y-axis.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``keras`` , ``torchvision`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Fliplr``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_flip.html#imgaug.augmenters.flip.Fliplr>`_ 

        if library = ``torchvision``:       (see: ``RandomHorizontalFlip)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomHorizontalFlip>`_ 
    
            p (float): probability of the image being flipped. Default value is 0.5
        


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.HorizontalFlip(p=1,  library="albumentations")
        aug = BA.HorizontalFlip(p=1,  library="imgaug")
        aug = BA.HorizontalFlip(p=1,  library="torchvision")
        aug = BA.HorizontalFlip(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.VerticalFlip:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Flip the input vertically around the x-axis.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``keras`` , ``torchvision`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Flipud``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_flip.html#imgaug.augmenters.flip.Flipud>`_ 

        if library = ``torchvision``:       (see: ``RandomVerticalFlip)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomVerticalFlip>`_ 
    
            p (float): probability of the image being flipped. Default value is 0.5
        


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.VerticalFlip(p=1,  library="albumentations")
        aug = BA.VerticalFlip(p=1,  library="imgaug")
        aug = BA.VerticalFlip(p=1,  library="torchvision")
        aug = BA.VerticalFlip(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ChannelShuffle:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly rearrange channels of the input RGB image.

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``albumentations`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``ChannelShuffle``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.ChannelShuffle>`_ 

            channels( None or imgaug.ALL or list of int, optional):
                Which channels are allowed to be shuffled with each other.
                If this is ``None`` or ``imgaug.ALL``, then all channels may be
                shuffled. If it is a ``list`` of ``int`` s,
                then only the channels with indices in that list may be shuffled.
                (Values start at ``0``. All channel indices in the list must exist in
                each image.)


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ChannelShuffle(p=1,  library="albumentations")
        aug = BA.ChannelShuffle(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Lambda:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A flexible transformation class for using user-defined transformation functions per targets.
    Function signature must include **kwargs to accept optinal arguments like interpolation method, image size, etc:

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``torchvision`` , ``albumentations`` .
								Default: `` albumentations``.
        image (callable): Image transformation function.
        mask (callable): Mask transformation function.
        keypoint (callable): Keypoint transformation function.
        bbox (callable): BBox transformation function.
        always_apply (bool): Indicates whether this transformation should be always applied.
        p (float): probability of applying the transform. Default: 1.0.

        if library = ``imgaug``:       (see: ``Lambda``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Lambda>`_ 

            func_images( None or callable, optional):
                The function to call for each batch of images.
                It must follow the form::


            func_heatmaps( None or callable, optional):
                The function to call for each batch of heatmaps.
                It must follow the form::


            func_segmentation_maps( None or callable, optional):
                The function to call for each batch of segmentation maps.
                It must follow the form::


            func_keypoints( None or callable, optional):
                The function to call for each batch of keypoints.
                It must follow the form::


            func_bounding_boxes( "keypoints" or None or callable, optional):
                The function to call for each batch of bounding boxes.
                It must follow the form::


            func_polygons( "keypoints" or None or callable, optional):
                The function to call for each batch of polygons.
                It must follow the form::


            func_line_strings( "keypoints" or None or callable, optional):
                The function to call for each batch of line strings.
                It must follow the form::


        if library = ``torchvision``:       (see: ``Lambda)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Lambda>`_ 
    
            lambd (function): Lambda/function to be used for transform.
        


    Targets:
        image, mask, bboxes, keypoints

    Image types:
        Any
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Lambda(p=1,  library="albumentations")
        aug = BA.Lambda(p=1,  library="imgaug")
        aug = BA.Lambda(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Autocontrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Autocontrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.Autocontrast>`_ 

            cutoff( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Percentage of values to cut off from the low and high end of each
                image's histogram, before stretching it to ``[0, 255]``.


            per_channel(  bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.


        if library = ``torchvision``:       (see: ``autocontrast)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#autocontrast>`_ 
    
            img (PIL Image or Tensor): Image on which autocontrast is applied.
                If img is torch Tensor, it is expected to be in [..., 1 or 3, H, W] format,
                where ... means it can have an arbitrary number of leading dimensions.
                If img is PIL Image, it is expected to be in mode "L" or "RGB".


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Autocontrast(p=1,  library="imgaug")
        aug = BA.Autocontrast(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Blur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Blur the input image using a random-sized kernel.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        blur_limit (int, (int, int)): maximum kernel size for blurring the input image.
            Should be in range [3, inf). Default: (3, 7).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``AverageBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.AverageBlur>`_ 

            k( int or tuple of int or tuple of tuple of int or imgaug.parameters.StochasticParameter or tuple of StochasticParameter, optional):
                Kernel size to use.


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Blur(p=1, blur_limit=[3, 7], library="albumentations")
        aug = BA.Blur(p=1, blur_limit=[3, 7], library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MedianBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Blur the input image using a median filter with a random aperture linear size.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        blur_limit (int): maximum aperture linear size for blurring the input image.
            Must be odd and in range [3, inf). Default: (3, 7).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``MedianBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.MedianBlur>`_ 

            k( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Kernel size.


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MedianBlur(p=1,  library="albumentations")
        aug = BA.MedianBlur(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Grayscale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Grayscale``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.Grayscale>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The alpha value of the grayscale image when overlayed over the
                old image. A value close to 1.0 means, that mostly the new grayscale
                image is visible. A value close to 0.0 means, that mostly the
                old image is visible.


        if library = ``torchvision``:       (see: ``Grayscale)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Grayscale>`_ 
    
            num_output_channels (int): (1 or 3) number of channels desired for output image


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Grayscale(p=1,  library="imgaug")
        aug = BA.Grayscale(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Scale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``Resize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Resize>`_ 
    
            size (sequence or int): Desired output size. If size is a sequence like
                (h, w), output size will be matched to this. If size is an int,
                smaller edge of the image will be matched to this number.
                i.e, if height > width, then image will be rescaled to
                (size * height / width, size).


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Scale(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomGrayscale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomGrayscale)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomGrayscale>`_ 
    
            p (float): probability that image should be converted to grayscale.


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomGrayscale(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Equalize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Equalize the image histogram.

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``torchvision`` , ``albumentations`` .
								Default: `` albumentations``.
        mode (str): {'cv', 'pil'}. Use OpenCV or Pillow equalization method.
        by_channels (bool): If True, use equalization by channels separately,
            else convert image to YCbCr representation and use equalization by `Y` channel.
        mask (np.ndarray, callable): If given, only the pixels selected by
            the mask are included in the analysis. Maybe 1 channel or 3 channel array or callable.
            Function signature must include `image` argument.
        mask_params (list of str): Params for mask function.

        if library = ``imgaug``:       (see: ``Equalize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.Equalize>`_ 

        if library = ``torchvision``:       (see: ``RandomEqualize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomEqualize>`_ 
    
            p (float): probability of the image being equalized. Default value is 0.5
        


    Targets:
        image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Equalize(p=1,  library="albumentations")
        aug = BA.Equalize(p=1,  library="imgaug")
        aug = BA.Equalize(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Brightness:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly change brightness of the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``keras`` , ``torchvision`` .
								Default: `` albumentations``.
        limit ((float, float) or float): factor range for changing brightness.
            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``AddToBrightness``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.AddToBrightness>`_ 

            add( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.airthmetic.Add`.


            to_colorspace( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.color.WithBrightnessChannels`.


        if library = ``torchvision``:       (see: ``ColorJitter)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#ColorJitter>`_ 
    
            brightness (float or tuple of float (min, max)): How much to jitter brightness.
                brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]
                or the given [min, max]. Should be non negative numbers.
            contrast (float or tuple of float (min, max)): How much to jitter contrast.
                contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]
                or the given [min, max]. Should be non negative numbers.
            saturation (float or tuple of float (min, max)): How much to jitter saturation.
                saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]
                or the given [min, max]. Should be non negative numbers.
            hue (float or tuple of float (min, max)): How much to jitter hue.
                hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].
                Should have 0<= hue <= 0.5 or -0.5 <= min <= max <= 0.5.
        


    if library = ``keras``:       (see: ``apply_brightness_shift``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/apply_brightness_shift>`_
    
            x: Input tensor. Must be 3D.
            brightness: Float. The new brightness value.
            channel_axis: Index of axis for channels in the input tensor.
    
        


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Brightness(p=1, limit=[-0.2, 0.2], library="albumentations")
        aug = BA.Brightness(p=1, limit=[-0.2, 0.2], library="imgaug")
        aug = BA.Brightness(p=1, limit=[-0.2, 0.2], library="torchvision")
        aug = BA.Brightness(p=1, limit=[-0.2, 0.2], library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Contrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly change contrast of the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        limit ((float, float) or float): factor range for changing contrast.
            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``MultiplyBrightness``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.MultiplyBrightness>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.airthmetic.Multiply`.


            to_colorspace( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.color.WithBrightnessChannels`.


        if library = ``torchvision``:       (see: ``ColorJitter)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#ColorJitter>`_ 
    
            brightness (float or tuple of float (min, max)): How much to jitter brightness.
                brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]
                or the given [min, max]. Should be non negative numbers.
            contrast (float or tuple of float (min, max)): How much to jitter contrast.
                contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]
                or the given [min, max]. Should be non negative numbers.
            saturation (float or tuple of float (min, max)): How much to jitter saturation.
                saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]
                or the given [min, max]. Should be non negative numbers.
            hue (float or tuple of float (min, max)): How much to jitter hue.
                hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].
                Should have 0<= hue <= 0.5 or -0.5 <= min <= max <= 0.5.
        


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Contrast(p=1, limit=[-0.2, 0.2], library="albumentations")
        aug = BA.Contrast(p=1, limit=[-0.2, 0.2], library="imgaug")
        aug = BA.Contrast(p=1, limit=[-0.2, 0.2], library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Emboss:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Emboss the input image and overlays the result with the original image.

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``albumentations`` .
								Default: `` albumentations``.
        alpha ((float, float)): range to choose the visibility of the embossed image. At 0, only the original image is
            visible,at 1.0 only its embossed version is visible. Default: (0.2, 0.5).
        strength ((float, float)): strength range of the embossing. Default: (0.2, 0.7).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Emboss``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_convolutional.html#imgaug.augmenters.convolutional.Emboss>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Blending factor of the embossed image. At ``0.0``, only the original
                image is visible, at ``1.0`` only its embossed version is visible.


            strength( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Parameter that controls the strength of the embossing.
                Sane values are somewhere in the interval ``[0.0, 2.0]`` with ``1.0``
                being the standard embossing effect. Default value is ``1.0``.


    Targets:
        image
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Emboss(p=1,  library="albumentations")
        aug = BA.Emboss(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CLAHE:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Apply Contrast Limited Adaptive Histogram Equalization to the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``imgaug`` , ``albumentations`` .
								Default: `` albumentations``.
        clip_limit (float or (float, float)): upper threshold value for contrast limiting.
            If clip_limit is a single float value, the range will be (1, clip_limit). Default: (1, 4).
        tile_grid_size ((int, int)): size of grid for histogram equalization. Default: (8, 8).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``CLAHE``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.CLAHE>`_ 

            clip_limit( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Clipping limit. Higher values result in stronger contrast. OpenCV
                uses a default of ``40``, though values around ``5`` seem to already
                produce decent contrast.


            tile_grid_size_px( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                Kernel size, i.e. size of each local neighbourhood in pixels.


            tile_grid_size_px_min( int, optional):
                Minimum kernel size in px, per axis. If the sampling results in a
                value lower than this minimum, it will be clipped to this value.


            to_colorspace( {"Lab", "HLS", "HSV"}, optional):
                Colorspace in which to perform CLAHE. For ``Lab``, CLAHE will only be
                applied to the first channel (``L``), for ``HLS`` to the
                second (``L``) and for ``HSV`` to the third (``V``). To apply CLAHE
                to all channels of an input image (without colorspace conversion),
                see ``imgaug.augmenters.contrast.AllChannelsCLAHE``.


    Targets:
        image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CLAHE(p=1,  library="albumentations")
        aug = BA.CLAHE(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Invert:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Invert the input image by subtracting pixel values from 255.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Invert``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Invert>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).


            min_value( None or number, optional):
                Minimum of the value range of input images, e.g. ``0`` for ``uint8``
                images. If set to ``None``, the value will be automatically derived
                from the image's dtype.


            max_value( None or number, optional):
                Maximum of the value range of input images, e.g. ``255`` for ``uint8``
                images. If set to ``None``, the value will be automatically derived
                from the image's dtype.


            threshold( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                A threshold to use in order to invert only numbers above or below
                the threshold. If ``None`` no thresholding will be used.


            invert_above_threshold( bool or float or imgaug.parameters.StochasticParameter, optional):
                If ``True``, only values ``>=threshold`` will be inverted.
                Otherwise, only values ``<threshold`` will be inverted.
                If a ``number``, then expected to be in the interval ``[0.0, 1.0]`` and
                denoting an imagewise probability. If a ``StochasticParameter`` then
                ``(N,)`` values will be sampled from the parameter per batch of size
                ``N`` and interpreted as ``True`` if ``>0.5``.
                If `threshold` is ``None`` this parameter has no effect.


        if library = ``torchvision``:       (see: ``RandomInvert)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomInvert>`_ 
    
            p (float): probability of the image being color inverted. Default value is 0.5
        


    Targets:
        image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Invert(p=1,  library="albumentations")
        aug = BA.Invert(p=1,  library="imgaug")
        aug = BA.Invert(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Posterize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Reduce the number of bits for each color channel.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        num_bits ((int, int) or int,
                  or list of ints [r, g, b],
                  or list of ints [[r1, r1], [g1, g2], [b1, b2]]): number of high bits.
            If num_bits is a single value, the range will be [num_bits, num_bits].
            Must be in range [0, 8]. Default: 4.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``UniformColorQuantizationToNBits``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.UniformColorQuantizationToNBits>`_ 

            nb_bits( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bits to keep in each image's array component.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.


        if library = ``torchvision``:       (see: ``RandomPosterize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomPosterize>`_ 
    
            bits (int): number of bits to keep for each channel (0-8)
            p (float): probability of the image being color inverted. Default value is 0.5
        


    Targets:
    image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Posterize(p=1, num_bits=4, library="albumentations")
        aug = BA.Posterize(p=1, num_bits=4, library="imgaug")
        aug = BA.Posterize(p=1, num_bits=4, library="torchvision")
        image_auged = aug(image=image)["image"]
                library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Posterize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.Posterize>`_ 

            nb_bits( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bits to keep in each image's array component.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Posterize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Saturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly changes the brightness, contrast, and saturation of an image. Compared to ColorJitter from torchvision,
    this transform gives a little bit different results because Pillow (used in torchvision) and OpenCV (used in
    Albumentations) transform an image to HSV format by different formulas. Another difference - Pillow uses uint8
    overflow, but we use value saturation.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        brightness (float or tuple of float (min, max)): How much to jitter brightness.
            brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]
            or the given [min, max]. Should be non negative numbers.
        contrast (float or tuple of float (min, max)): How much to jitter contrast.
            contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]
            or the given [min, max]. Should be non negative numbers.
        saturation (float or tuple of float (min, max)): How much to jitter saturation.
            saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]
            or the given [min, max]. Should be non negative numbers.
        hue (float or tuple of float (min, max)): How much to jitter hue.
            hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].
            Should have 0 <= hue <= 0.5 or -0.5 <= min <= max <= 0.5.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Saturation(p=1, saturation=0.2, library="albumentations")
        aug = BA.Saturation(p=1, saturation=0.2, library="imgaug")
        aug = BA.Saturation(p=1, saturation=0.2, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Sharpen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sharpen the input image and overlays the result with the original image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        alpha ((float, float)): range to choose the visibility of the sharpened image. At 0, only the original image is
            visible, at 1.0 only its sharpened version is visible. Default: (0.2, 0.5).
        lightness ((float, float)): range to choose the lightness of the sharpened image. Default: (0.5, 1.0).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Sharpen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_convolutional.html#imgaug.augmenters.convolutional.Sharpen>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Blending factor of the sharpened image. At ``0.0``, only the original
                image is visible, at ``1.0`` only its sharpened version is visible.


            lightness( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Lightness/brightness of the sharped image.
                Sane values are somewhere in the interval ``[0.5, 2.0]``.
                The value ``0.0`` results in an edge map. Values higher than ``1.0``
                create bright images. Default value is ``1.0``.


        if library = ``torchvision``:       (see: ``adjust_sharpness)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#adjust_sharpness>`_ 
    
            img (PIL Image or Tensor): Image to be adjusted.
                If img is torch Tensor, it is expected to be in [..., 1 or 3, H, W] format,
                where ... means it can have an arbitrary number of leading dimensions.
            sharpness_factor (float):  How much to adjust the sharpness. Can be
                any non negative number. 0 gives a blurred image, 1 gives the
                original image while 2 increases the sharpness by a factor of 2.

    Targets:
        image
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Sharpen(p=1, alpha=[0.2, 0.5],lightness=[0.5, 1.0], library="albumentations")
        aug = BA.Sharpen(p=1, alpha=[0.2, 0.5],lightness=[0.5, 1.0], library="imgaug")
        aug = BA.Sharpen(p=1, alpha=[0.2, 0.5],lightness=[0.5, 1.0], library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Solarize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Invert all pixel values above a threshold.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        threshold ((int, int) or int, or (float, float) or float): range for solarizing threshold.
        If threshold is a single value, the range will be [threshold, threshold]. Default: 128.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Solarize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Solarize>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                See :class:`Invert`.


            min_value( None or number, optional):
                See :class:`Invert`.


            max_value( None or number, optional):
                See :class:`Invert`.


            threshold( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`Invert`.


            invert_above_threshold( bool or float or imgaug.parameters.StochasticParameter, optional):
                See :class:`Invert`.


        if library = ``torchvision``:       (see: ``RandomSolarize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomSolarize>`_ 
    
            threshold (float): all pixels equal or above this value are inverted.
            p (float): probability of the image being color inverted. Default value is 0.5
        


    Targets:
        image

    Image types:
        any
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Solarize(p=1, threshold=128, library="albumentations")
        aug = BA.Solarize(p=1, threshold=128, library="imgaug")
        aug = BA.Solarize(p=1, threshold=128, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PerspectiveTransform:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PerspectiveTransform``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.PerspectiveTransform>`_ 

            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Standard deviation of the normal distributions. These are used to
                sample the random distances of the subimage's corners from the full
                image's corners. The sampled values reflect percentage values (with
                respect to image height/width). Recommended values are in the range
                ``0.0`` to ``0.1``.


            cval( number or tuple of number or list of number or imaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value used to fill up pixels in the result image that
                didn't exist in the input image (e.g. when translating to the left,
                some new pixels are created at the right). Such a fill-up with a
                constant value only happens, when `mode` is ``constant``.
                The expected value range is ``[0, 255]`` for ``uint8`` images.
                It may be a float value.


            mode( int or str or list of str or list of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Parameter that defines the handling of newly created pixels.
                Same meaning as in OpenCV's border mode. Let ``abcdefgh`` be an image's
                content and ``|`` be an image boundary, then:


            keep_size( bool, optional):
                Whether to resize image's back to their original size after applying
                the perspective transform. If set to ``False``, the resulting images
                may end up having different shapes and will always be a list, never
                an array.


            fit_output( bool, optional):
                If ``True``, the image plane size and position will be adjusted
                to still capture the whole image after perspective transformation.
                (Followed by image resizing if `keep_size` is set to ``True``.)
                Otherwise, parts of the transformed image may be outside of the image
                plane.
                This setting should not be set to ``True`` when using large `scale`
                values as it could lead to very large images.


            polygon_recoverer( 'auto' or None or imgaug.augmentables.polygons._ConcavePolygonRecoverer, optional):
                The class to use to repair invalid polygons.
                If ``"auto"``, a new instance of
                :class`imgaug.augmentables.polygons._ConcavePolygonRecoverer`
                will be created.
                If ``None``, no polygon recoverer will be used.
                If an object, then that object will be used and must provide a
                ``recover_from()`` method, similar to
                :class:`~imgaug.augmentables.polygons._ConcavePolygonRecoverer`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PerspectiveTransform(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CoarseDropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

CoarseDropout of the rectangular regions in the image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        max_holes (int): Maximum number of regions to zero out.
        max_height (int): Maximum height of the hole.
        max_width (int): Maximum width of the hole.
        min_holes (int): Minimum number of regions to zero out. If `None`,
            `min_holes` is be set to `max_holes`. Default: `None`.
        min_height (int): Minimum height of the hole. Default: None. If `None`,
            `min_height` is set to `max_height`. Default: `None`.
        min_width (int): Minimum width of the hole. If `None`, `min_height` is
            set to `max_width`. Default: `None`.
        fill_value (int, float, list of int, list of float): value for dropped pixels.
        mask_fill_value (int, float, list of int, list of float): fill value for dropped pixels
            in mask. If `None` - mask is not affected. Default: `None`.

        if library = ``imgaug``:       (see: ``CoarseDropout``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.CoarseDropout>`_ 

            size_px( None or int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the dropout
                mask in absolute pixel dimensions.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being dropped (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            size_percent( None or float or tuple of float or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the dropout
                mask *in percent* of the input image.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being dropped (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).


            min_size( int, optional):
                Minimum height and width of the low resolution mask. If
                `size_percent` or `size_px` leads to a lower value than this,
                `min_size` will be used instead. This should never have a value of
                less than ``2``, otherwise one may end up with a ``1x1`` low resolution
                mask, leading easily to the whole image being dropped.


    Targets:
        image, mask

    Image types:
        uint8, float32

    Reference:
    |  https://arxiv.org/abs/1708.04552
    |  https://github.com/uoguelph-mlrg/Cutout/blob/master/util/cutout.py
    |  https://github.com/aleju/imgaug/blob/master/imgaug/augmenters/arithmetic.py
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CoarseDropout(p=1,  library="albumentations")
        aug = BA.CoarseDropout(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OverlayText:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.JpegCompression:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Decrease Jpeg compression of an image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        quality_lower (float): lower bound on the jpeg quality. Should be in [0, 100] range
        quality_upper (float): upper bound on the jpeg quality. Should be in [0, 100] range

        if library = ``imgaug``:       (see: ``JpegCompression``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression>`_ 

            compression( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Degree of compression used during JPEG compression within value range
                ``[0, 100]``. Higher values denote stronger compression and will cause
                low-frequency components to disappear. Note that JPEG's compression
                strength is also often set as a *quality*, which is the inverse of this
                parameter. Common choices for the *quality* setting are around 80 to 95,
                depending on the image. This translates here to a *compression*
                parameter of around 20 to 5.


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.JpegCompression(p=1, quality_lower=99,quality_upper=100, library="albumentations")
        aug = BA.JpegCompression(p=1, quality_lower=99,quality_upper=100, library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ColorJitter:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly changes the brightness, contrast, and saturation of an image. Compared to ColorJitter from torchvision,
    this transform gives a little bit different results because Pillow (used in torchvision) and OpenCV (used in
    Albumentations) transform an image to HSV format by different formulas. Another difference - Pillow uses uint8
    overflow, but we use value saturation.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``torchvision`` .
								Default: `` albumentations``.
        brightness (float or tuple of float (min, max)): How much to jitter brightness.
            brightness_factor is chosen uniformly from [max(0, 1 - brightness), 1 + brightness]
            or the given [min, max]. Should be non negative numbers.
        contrast (float or tuple of float (min, max)): How much to jitter contrast.
            contrast_factor is chosen uniformly from [max(0, 1 - contrast), 1 + contrast]
            or the given [min, max]. Should be non negative numbers.
        saturation (float or tuple of float (min, max)): How much to jitter saturation.
            saturation_factor is chosen uniformly from [max(0, 1 - saturation), 1 + saturation]
            or the given [min, max]. Should be non negative numbers.
        hue (float or tuple of float (min, max)): How much to jitter hue.
            hue_factor is chosen uniformly from [-hue, hue] or the given [min, max].
            Should have 0 <= hue <= 0.5 or -0.5 <= min <= max <= 0.5.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ColorJitter(p=1, brightness=0.2,contrast=0.2,saturation=0.2,hue=0.2, library="albumentations")
        aug = BA.ColorJitter(p=1, brightness=0.2,contrast=0.2,saturation=0.2,hue=0.2, library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Superpixels:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Transform images partially/completely to their superpixel representation.
    This implementation uses skimage's version of the SLIC algorithm.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        p_replace (float or tuple of float): Defines for any segment the probability that the pixels within that
            segment are replaced by their average color (otherwise, the pixels are not changed).
            Examples:
                * A probability of ``0.0`` would mean, that the pixels in no
                  segment are replaced by their average color (image is not
                  changed at all).
                * A probability of ``0.5`` would mean, that around half of all
                  segments are replaced by their average color.
                * A probability of ``1.0`` would mean, that all segments are
                  replaced by their average color (resulting in a voronoi
                  image).
            Behaviour based on chosen data types for this parameter:
                * If a ``float``, then that ``flat`` will always be used.
                * If ``tuple`` ``(a, b)``, then a random probability will be
                  sampled from the interval ``[a, b]`` per image.
        n_segments (int, or tuple of int): Rough target number of how many superpixels to generate (the algorithm
            may deviate from this number). Lower value will lead to coarser superpixels.
            Higher values are computationally more intensive and will hence lead to a slowdown
            * If a single ``int``, then that value will always be used as the
              number of segments.
            * If a ``tuple`` ``(a, b)``, then a value from the discrete
              interval ``[a..b]`` will be sampled per image.
        max_size (int or None): Maximum image size at which the augmentation is performed.
            If the width or height of an image exceeds this value, it will be
            downscaled before the augmentation so that the longest side matches `max_size`.
            This is done to speed up the process. The final output image has the same size as the input image.
            Note that in case `p_replace` is below ``1.0``,
            the down-/upscaling will affect the not-replaced pixels too.
            Use ``None`` to apply no down-/upscaling.
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``Superpixels``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.Superpixels>`_ 

            p_replace( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Defines for any segment the probability that the pixels within that
                segment are replaced by their average color (otherwise, the pixels
                are not changed).
                Examples:


            n_segments( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Rough target number of how many superpixels to generate (the algorithm
                may deviate from this number). Lower value will lead to coarser
                superpixels. Higher values are computationally more intensive and
                will hence lead to a slowdown.


            max_size( int or None, optional):
                Maximum image size at which the augmentation is performed.
                If the width or height of an image exceeds this value, it will be
                downscaled before the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the process. The final output image has the
                same size as the input image. Note that in case `p_replace` is below
                ``1.0``, the down-/upscaling will affect the not-replaced pixels too.
                Use ``None`` to apply no down-/upscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.


    Targets:
        image
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Superpixels(p=1,  library="albumentations")
        aug = BA.Superpixels(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GaussianNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AdditiveGaussianNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.AdditiveGaussianNoise>`_ 

            loc( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Mean of the normal distribution from which the noise is sampled.


            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Standard deviation of the normal distribution that generates the noise.
                Must be ``>=0``. If ``0`` then `loc` will simply be added to all
                pixels.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GaussianNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ShotNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ImpulseNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ImpulseNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.ImpulseNoise>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ImpulseNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GlassBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Apply glass noise to the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        sigma (float): standard deviation for Gaussian kernel.
        max_delta (int): max distance between pixels which are swapped.
        iterations (int): number of repeats.
            Should be in range [1, inf). Default: (2).
        mode (str): mode of computation: fast or exact. Default: "fast".
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32

    Reference:
    |  https://arxiv.org/abs/1903.12261
    |  https://github.com/hendrycks/robustness/blob/master/ImageNet-C/create_c/make_imagenet_c.py
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GlassBlur(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MotionBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Apply motion blur to the input image using a random-sized kernel.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        blur_limit (int): maximum kernel size for blurring the input image.
            Should be in range [3, inf). Default: (3, 7).
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``MotionBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.MotionBlur>`_ 

            k( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Kernel size to use.


            angle( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Angle of the motion blur in degrees (clockwise, relative to top center
                direction).


            direction( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Forward/backward direction of the motion blur. Lower values towards
                ``-1.0`` will point the motion blur towards the back (with angle
                provided via `angle`). Higher values towards ``1.0`` will point the
                motion blur forward. A value of ``0.0`` leads to a uniformly (but
                still angled) motion blur.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use when rotating the kernel according to
                `angle`.
                See :func:`~imgaug.augmenters.geometric.Affine.__init__`.
                Recommended to be ``0`` or ``1``, with ``0`` being faster, but less
                continuous/smooth as `angle` is changed, particularly around multiple
                of ``45`` degrees.


    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MotionBlur(p=1,  library="albumentations")
        aug = BA.MotionBlur(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GaussianBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Blur the input image using a Gaussian filter with a random kernel size.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``torchvision`` , ``imgaug`` .
								Default: `` albumentations``.
        blur_limit (int, (int, int)): maximum Gaussian kernel size for blurring the input image.
            Must be zero or odd and in range [0, inf). If set to 0 it will be computed from sigma
            as `round(sigma * (3 if img.dtype == np.uint8 else 4) * 2 + 1) + 1`.
            If set single value `blur_limit` will be in range (0, blur_limit).
            Default: (3, 7).
        sigma_limit (float, (float, float)): Gaussian kernel standard deviation. Must be greater in range [0, inf).
            If set single value `sigma_limit` will be in range (0, sigma_limit).
            If set to 0 sigma will be computed as `sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8`. Default: 0.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``GaussianBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.GaussianBlur>`_ 

            sigma( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Standard deviation of the gaussian kernel.
                Values in the range ``0.0`` (no blur) to ``3.0`` (strong blur) are
                common.


        if library = ``torchvision``:       (see: ``GaussianBlur)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#GaussianBlur>`_ 
    
            kernel_size (int or sequence): Size of the Gaussian kernel.
            sigma (float or tuple of float (min, max)): Standard deviation to be used for
                creating kernel to perform blurring. If float, sigma is fixed. If it is tuple
                of float (min, max), sigma is chosen uniformly at random to lie in the
                given range.

    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GaussianBlur(p=1,  library="albumentations")
        aug = BA.GaussianBlur(p=1,  library="imgaug")
        aug = BA.GaussianBlur(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Snow:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Bleach out some pixel values simulating snow.

    From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        snow_point_lower (float): lower_bond of the amount of snow. Should be in [0, 1] range
        snow_point_upper (float): upper_bond of the amount of snow. Should be in [0, 1] range
        brightness_coeff (float): larger number will lead to a more snow on the image. Should be >= 0

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Snow(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Fog:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Simulates fog for the image

    From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        fog_coef_lower (float): lower limit for fog intensity coefficient. Should be in [0, 1] range.
        fog_coef_upper (float): upper limit for fog intensity coefficient. Should be in [0, 1] range.
        alpha_coef (float): transparency of the fog circles. Should be in [0, 1] range.

        if library = ``imgaug``:       (see: ``Fog``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.Fog>`_ 

    Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Fog(p=1,  library="albumentations")
        aug = BA.Fog(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ElasticTransform:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Elastic deformation of images as described in [Simard2003]_ (with modifications).
    Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5

    .. [Simard2003] Simard, Steinkraus and Platt, "Best Practices for
         Convolutional Neural Networks applied to Visual Document Analysis", in
         Proc. of the International Conference on Document Analysis and
         Recognition, 2003.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` .
								Default: `` albumentations``.
        alpha (float):
        sigma (float): Gaussian filter parameter.
        alpha_affine (float): The range will be (-alpha_affine, alpha_affine)
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of ints,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.
        approximate (boolean): Whether to smooth displacement map with fixed kernel size.
                               Enabling this option gives ~2X speedup on large images.

        if library = ``imgaug``:       (see: ``ElasticTransformation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ElasticTransformation>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Strength of the distortion field. Higher values mean that pixels are
                moved further with respect to the distortion field's direction. Set
                this to around 10 times the value of `sigma` for visible effects.


            sigma( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Standard deviation of the gaussian kernel used to smooth the distortion
                fields. Higher values (for ``128x128`` images around 5.0) lead to more
                water-like effects, while lower values (for ``128x128`` images
                around ``1.0`` and lower) lead to more noisy, pixelated images. Set
                this to around 1/10th of `alpha` for visible effects.


            order( int or list of int or imaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in
                :func:`scipy.ndimage.map_coordinates` and may take any integer value
                in the range ``0`` to ``5``, where orders close to ``0`` are faster.


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant intensity value used to fill in new pixels.
                This value is only used if `mode` is set to ``constant``.
                For standard ``uint8`` images (value range ``0`` to ``255``), this
                value may also should also be in the range ``0`` to ``255``. It may
                be a ``float`` value, even for images with integer dtypes.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Parameter that defines the handling of newly created pixels.
                May take the same values as in :func:`scipy.ndimage.map_coordinates`,
                i.e. ``constant``, ``nearest``, ``reflect`` or ``wrap``.


            polygon_recoverer( 'auto' or None or imgaug.augmentables.polygons._ConcavePolygonRecoverer, optional):
                The class to use to repair invalid polygons.
                If ``"auto"``, a new instance of
                :class`imgaug.augmentables.polygons._ConcavePolygonRecoverer`
                will be created.
                If ``None``, no polygon recoverer will be used.
                If an object, then that object will be used and must provide a
                ``recover_from()`` method, similar to
                :class:`~imgaug.augmentables.polygons._ConcavePolygonRecoverer`.


    Targets:
        image, mask

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ElasticTransform(p=1,  library="albumentations")
        aug = BA.ElasticTransform(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Pixelization:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Randomflip:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Rerange:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RGB2Gray:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AdjustGamma:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SegRescale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PhotoMetricDistortion:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ShiftScaleRotate:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly apply affine transforms: translate, scale and rotate the input.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        shift_limit ((float, float) or float): shift factor range for both height and width. If shift_limit
            is a single float value, the range will be (-shift_limit, shift_limit). Absolute values for lower and
            upper bounds should lie in range [0, 1]. Default: (-0.0625, 0.0625).
        scale_limit ((float, float) or float): scaling factor range. If scale_limit is a single float value, the
            range will be (-scale_limit, scale_limit). Default: (-0.1, 0.1).
        rotate_limit ((int, int) or int): rotation range. If rotate_limit is a single int value, the
            range will be (-rotate_limit, rotate_limit). Default: (-45, 45).
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of int, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of int,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.
        shift_limit_x ((float, float) or float): shift factor range for width. If it is set then this value
            instead of shift_limit will be used for shifting width.  If shift_limit_x is a single float value,
            the range will be (-shift_limit_x, shift_limit_x). Absolute values for lower and upper bounds should lie in
            the range [0, 1]. Default: None.
        shift_limit_y ((float, float) or float): shift factor range for height. If it is set then this value
            instead of shift_limit will be used for shifting height.  If shift_limit_y is a single float value,
            the range will be (-shift_limit_y, shift_limit_y). Absolute values for lower and upper bounds should lie
            in the range [0, 1]. Default: None.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ShiftScaleRotate(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Perspective:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Perform a random four point perspective transform of the input.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        scale (float or (float, float)): standard deviation of the normal distributions. These are used to sample
            the random distances of the subimage's corners from the full image's corners.
            If scale is a single float value, the range will be (0, scale). Default: (0.05, 0.1).
        keep_size (bool): Whether to resize image’s back to their original size after applying the perspective
            transform. If set to False, the resulting images may end up having different shapes
            and will always be a list, never an array. Default: True
        pad_mode (OpenCV flag): OpenCV border mode.
        pad_val (int, float, list of int, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
            Default: 0
        mask_pad_val (int, float, list of int, list of float): padding value for mask
            if border_mode is cv2.BORDER_CONSTANT. Default: 0
        fit_output (bool): If True, the image plane size and position will be adjusted to still capture
            the whole image after perspective transformation. (Followed by image resizing if keep_size is set to True.)
            Otherwise, parts of the transformed image may be outside of the image plane.
            This setting should not be set to True when using large scale values as it could lead to very large images.
            Default: False
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, keypoints, bboxes

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Perspective(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomScale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly resize the input. Output image size is different from the input image size.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        scale_limit ((float, float) or float): scaling factor range. If scale_limit is a single float value, the
            range will be (1 - scale_limit, 1 + scale_limit). Default: (0.9, 1.1).
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomScale(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.LongestMaxSize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Rescale an image so that maximum side is equal to max_size, keeping the aspect ratio of the initial image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        max_size (int): maximum size of the image after the transformation.
        interpolation (OpenCV flag): interpolation method. Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.LongestMaxSize(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SmallestMaxSize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Rescale an image so that minimum side is equal to max_size, keeping the aspect ratio of the initial image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        max_size (int): maximum size of smallest side of the image after the transformation.
        interpolation (OpenCV flag): interpolation method. Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SmallestMaxSize(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomRotate90:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly rotate the input by 90 degrees zero or more times.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomRotate90(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SafeRotate:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Rotate the input inside the input's frame by an angle selected randomly from the uniform distribution.

    The resulting image may have artifacts in it. After rotation, the image may have a different aspect ratio, and
    after resizing, it returns to its original shape with the original aspect ratio of the image. For these reason we
    may see some artifacts.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        limit ((int, int) or int): range from which a random angle is picked. If limit is a single int
            an angle is picked from (-limit, limit). Default: (-90, 90)
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of ints,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SafeRotate(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropNonEmptyMaskIfExists:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop area with mask if mask is non-empty, else make random crop.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        height (int): vertical size of crop in pixels
        width (int): horizontal size of crop in pixels
        ignore_values (list of int): values to ignore in mask, `0` values are always ignored
            (e.g. if background value is 5 set `ignore_values=[5]` to ignore)
        ignore_channels (list of int): channels to ignore in mask
            (e.g. if background is a first channel set `ignore_channels=[0]` to ignore)
        p (float): probability of applying the transform. Default: 1.0.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropNonEmptyMaskIfExists(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomCropNearBBox:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop bbox from image with random shift by x,y coordinates

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        max_part_shift (float): float value in (0.0, 1.0) range. Default 0.3
        p (float): probability of applying the transform. Default: 1.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomCropNearBBox(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomSizedBBoxSafeCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Crop a random part of the input and rescale it to some size without loss of bboxes.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        height (int): height after crop and resize.
        width (int): width after crop and resize.
        erosion_rate (float): erosion rate applied on input image height before crop.
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        p (float): probability of applying the transform. Default: 1.

        Targets:
        image, mask, bboxes

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomSizedBBoxSafeCrop(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Transpose:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Transpose the input by swapping rows and columns.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image, mask, bboxes, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Transpose(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomGamma:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        gamma_limit (float or (float, float)): If gamma_limit is a single float value,
            the range will be (-gamma_limit, gamma_limit). Default: (80, 120).
        eps: Deprecated.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomGamma(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OpticalDistortion:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        distort_limit (float, (float, float)): If distort_limit is a single float, the range
            will be (-distort_limit, distort_limit). Default: (-0.05, 0.05).
        shift_limit (float, (float, float))): If shift_limit is a single float, the range
            will be (-shift_limit, shift_limit). Default: (-0.05, 0.05).
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of ints,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.

        Targets:
        image, mask

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.OpticalDistortion(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GridDistortion:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        num_steps (int): count of grid cells on each side.
        distort_limit (float, (float, float)): If distort_limit is a single float, the range
            will be (-distort_limit, distort_limit). Default: (-0.03, 0.03).
        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:
            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.
            Default: cv2.INTER_LINEAR.
        border_mode (OpenCV flag): flag that is used to specify the pixel extrapolation method. Should be one of:
            cv2.BORDER_CONSTANT, cv2.BORDER_REPLICATE, cv2.BORDER_REFLECT, cv2.BORDER_WRAP, cv2.BORDER_REFLECT_101.
            Default: cv2.BORDER_REFLECT_101
        value (int, float, list of ints, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of ints,
                    list of float): padding value if border_mode is cv2.BORDER_CONSTANT applied for masks.

        Targets:
        image, mask

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GridDistortion(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomGridShuffle:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Random shuffle grid's cells on image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        grid ((int, int)): size of grid for splitting image.

        Targets:
        image, mask

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomGridShuffle(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.HueSaturationValue:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly change hue, saturation and value of the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        hue_shift_limit ((int, int) or int): range for changing hue. If hue_shift_limit is a single int, the range
            will be (-hue_shift_limit, hue_shift_limit). Default: (-20, 20).
        sat_shift_limit ((int, int) or int): range for changing saturation. If sat_shift_limit is a single int,
            the range will be (-sat_shift_limit, sat_shift_limit). Default: (-30, 30).
        val_shift_limit ((int, int) or int): range for changing value. If val_shift_limit is a single int, the range
            will be (-val_shift_limit, val_shift_limit). Default: (-20, 20).
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.HueSaturationValue(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadIfNeeded:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pad side of the image / max if side is less than desired number.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        min_height (int): minimal result image height.
        min_width (int): minimal result image width.
        pad_height_divisor (int): if not None, ensures image height is dividable by value of this argument.
        pad_width_divisor (int): if not None, ensures image width is dividable by value of this argument.
        position (Union[str, PositionType]): Position of the image. should be PositionType.CENTER or
            PositionType.TOP_LEFT or PositionType.TOP_RIGHT or PositionType.BOTTOM_LEFT or PositionType.BOTTOM_RIGHT.
            Default: PositionType.CENTER.
        border_mode (OpenCV flag): OpenCV border mode.
        value (int, float, list of int, list of float): padding value if border_mode is cv2.BORDER_CONSTANT.
        mask_value (int, float,
                    list of int,
                    list of float): padding value for mask if border_mode is cv2.BORDER_CONSTANT.
        p (float): probability of applying the transform. Default: 1.0.

        Targets:
        image, mask, bbox, keypoints

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadIfNeeded(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RGBShift:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly shift values for each channel of the input RGB image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        r_shift_limit ((int, int) or int): range for changing values for the red channel. If r_shift_limit is a single
            int, the range will be (-r_shift_limit, r_shift_limit). Default: (-20, 20).
        g_shift_limit ((int, int) or int): range for changing values for the green channel. If g_shift_limit is a
            single int, the range  will be (-g_shift_limit, g_shift_limit). Default: (-20, 20).
        b_shift_limit ((int, int) or int): range for changing values for the blue channel. If b_shift_limit is a single
            int, the range will be (-b_shift_limit, b_shift_limit). Default: (-20, 20).
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RGBShift(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GaussNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Apply gaussian noise to the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        var_limit ((float, float) or float): variance range for noise. If var_limit is a single float, the range
            will be (0, var_limit). Default: (10.0, 50.0).
        mean (float): mean of the noise. Default: 0
        per_channel (bool): if set to True, noise will be sampled for each channel independently.
            Otherwise, the noise will be sampled once for all channels. Default: True
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GaussNoise(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ToGray:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Convert the input RGB image to grayscale. If the mean pixel value for the resulting image is greater
    than 127, invert the resulting grayscale image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ToGray(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ToSepia:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Applies sepia filter to the input RGB image

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ToSepia(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ImageCompression:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Decrease Jpeg, WebP compression of an image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        quality_lower (float): lower bound on the image quality.
                               Should be in [0, 100] range for jpeg and [1, 100] for webp.
        quality_upper (float): upper bound on the image quality.
                               Should be in [0, 100] range for jpeg and [1, 100] for webp.
        compression_type (ImageCompressionType): should be ImageCompressionType.JPEG or ImageCompressionType.WEBP.
            Default: ImageCompressionType.JPEG

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ImageCompression(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ToFloat:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Divide pixel values by `max_value` to get a float32 output array where all values lie in the range [0, 1.0].
    If `max_value` is None the transform will try to infer the maximum value by inspecting the data type of the input
    image.

    See Also:
        :class:`~albumentations.augmentations.transforms.FromFloat`

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        max_value (float): maximum possible input value. Default: None.
        p (float): probability of applying the transform. Default: 1.0.

        Targets:
        image

    Image types:
        any type

    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ToFloat(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FromFloat:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Take an input array where all values should lie in the range [0, 1.0], multiply them by `max_value` and then
    cast the resulted value to a type specified by `dtype`. If `max_value` is None the transform will try to infer
    the maximum value for the data type from the `dtype` argument.

    This is the inverse transform for :class:`~albumentations.augmentations.transforms.ToFloat`.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        max_value (float): maximum possible input value. Default: None.
        dtype (string or numpy data type): data type of the output. See the `'Data types' page from the NumPy docs`_.
            Default: 'uint16'.
        p (float): probability of applying the transform. Default: 1.0.

        Targets:
        image

    Image types:
        float32

    .. _'Data types' page from the NumPy docs:
       https://docs.scipy.org/doc/numpy/user/basics.types.html
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FromFloat(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomBrightnessContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly change brightness and contrast of the input image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        brightness_limit ((float, float) or float): factor range for changing brightness.
            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).
        contrast_limit ((float, float) or float): factor range for changing contrast.
            If limit is a single float, the range will be (-limit, limit). Default: (-0.2, 0.2).
        brightness_by_max (Boolean): If True adjust contrast by image dtype maximum,
            else adjust contrast by image mean.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomBrightnessContrast(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomRain:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Adds rain effects.

    From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        slant_lower: should be in range [-20, 20].
        slant_upper: should be in range [-20, 20].
        drop_length: should be in range [0, 100].
        drop_width: should be in range [1, 5].
        drop_color (list of (r, g, b)): rain lines color.
        blur_value (int): rainy view are blurry
        brightness_coefficient (float): rainy days are usually shady. Should be in range [0, 1].
        rain_type: One of [None, "drizzle", "heavy", "torrestial"]

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomRain(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomSunFlare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Simulates Sun Flare for the image

    From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        flare_roi (float, float, float, float): region of the image where flare will
            appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1].
        angle_lower (float): should be in range [0, `angle_upper`].
        angle_upper (float): should be in range [`angle_lower`, 1].
        num_flare_circles_lower (int): lower limit for the number of flare circles.
            Should be in range [0, `num_flare_circles_upper`].
        num_flare_circles_upper (int): upper limit for the number of flare circles.
            Should be in range [`num_flare_circles_lower`, inf].
        src_radius (int):
        src_color ((int, int, int)): color of the flare

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomSunFlare(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomShadow:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Simulates shadows for the image

    From https://github.com/UjjwalSaxena/Automold--Road-Augmentation-Library

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        shadow_roi (float, float, float, float): region of the image where shadows
            will appear (x_min, y_min, x_max, y_max). All values should be in range [0, 1].
        num_shadows_lower (int): Lower limit for the possible number of shadows.
            Should be in range [0, `num_shadows_upper`].
        num_shadows_upper (int): Lower limit for the possible number of shadows.
            Should be in range [`num_shadows_lower`, inf].
        shadow_dimension (int): number of edges in the shadow polygons

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomShadow(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomToneCurve:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly change the relationship between bright and dark areas of the image by manipulating its tone curve.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        scale (float): standard deviation of the normal distribution.
            Used to sample random distances to move two control points that modify the image's curve.
            Values should be in range [0, 1]. Default: 0.1


        Targets:
        image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomToneCurve(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ChannelDropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Randomly Drop Channels in the input Image.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        channel_drop_range (int, int): range from which we choose the number of channels to drop.
        fill_value (int, float): pixel value for the dropped channel.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8, uint16, unit32, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ChannelDropout(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ISONoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Apply camera sensor noise.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        color_shift (float, float): variance range for color hue change.
            Measured as a fraction of 360 degree Hue angle in HLS colorspace.
        intensity ((float, float): Multiplicative factor that control strength
            of color and luminace noise.
        p (float): probability of applying the transform. Default: 0.5.

        Targets:
        image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ISONoise(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Downscale:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Decreases image quality by downscaling and upscaling back.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        scale_min (float): lower bound on the image scale. Should be < 1.
        scale_max (float):  lower bound on the image scale. Should be .
        interpolation: cv2 interpolation method. cv2.INTER_NEAREST by default

        Targets:
        image

    Image types:
        uint8, float32
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Downscale(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MultiplicativeNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Multiply image to random number or array of numbers.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        multiplier (float or tuple of floats): If single float image will be multiplied to this number.
            If tuple of float multiplier will be in range `[multiplier[0], multiplier[1])`. Default: (0.9, 1.1).
        per_channel (bool): If `False`, same values for all channels will be used.
            If `True` use sample values for each channels. Default False.
        elementwise (bool): If `False` multiply multiply all pixels in an image with a random value sampled once.
            If `True` Multiply image pixels with values that are pixelwise randomly sampled. Defaule: False.

        Targets:
        image

    Image types:
        Any
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MultiplicativeNoise(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FancyPCA:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Augment RGB image using FancyPCA from Krizhevsky's paper
    "ImageNet Classification with Deep Convolutional Neural Networks"

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        alpha (float):  how much to perturb/scale the eigen vecs and vals.
            scale is samples from gaussian distribution (mu=0, sigma=alpha)

        Targets:
        image

    Image types:
        3-channel uint8 images only

    Credit:
        http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf
        https://deshanadesai.github.io/notes/Fancy-PCA-with-Scikit-Image
        https://pixelatedbrian.github.io/2018-04-29-fancy_pca/
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FancyPCA(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MaskDropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


    Image & mask augmentation that zero out mask and image regions corresponding
    to randomly chosen object instance from mask.

    Mask must be single-channel image, zero values treated as background.
    Image can be any number of channels.

    Inspired by https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/114254
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MaskDropout(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GridDropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

GridDropout, drops out rectangular regions of an image and the corresponding mask in a grid fashion.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` .
								Default: `` albumentations``.
        ratio (float): the ratio of the mask holes to the unit_size (same for horizontal and vertical directions).
            Must be between 0 and 1. Default: 0.5.
        unit_size_min (int): minimum size of the grid unit. Must be between 2 and the image shorter edge.
            If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: `None`.
        unit_size_max (int): maximum size of the grid unit. Must be between 2 and the image shorter edge.
            If 'None', holes_number_x and holes_number_y are used to setup the grid. Default: `None`.
        holes_number_x (int): the number of grid units in x direction. Must be between 1 and image width//2.
            If 'None', grid unit width is set as image_width//10. Default: `None`.
        holes_number_y (int): the number of grid units in y direction. Must be between 1 and image height//2.
            If `None`, grid unit height is set equal to the grid unit width or image height, whatever is smaller.
        shift_x (int): offsets of the grid start in x direction from (0,0) coordinate.
            Clipped between 0 and grid unit_width - hole_width. Default: 0.
        shift_y (int): offsets of the grid start in y direction from (0,0) coordinate.
            Clipped between 0 and grid unit height - hole_height. Default: 0.
        random_offset (boolean): weather to offset the grid randomly between 0 and grid unit size - hole size
            If 'True', entered shift_x, shift_y are ignored and set randomly. Default: `False`.
        fill_value (int): value for the dropped pixels. Default = 0
        mask_fill_value (int): value for the dropped pixels in mask.
            If `None`, transformation is not applied to the mask. Default: `None`.

        Targets:
        image, mask

    Image types:
        uint8, float32

    References:
        https://arxiv.org/abs/2001.04086

    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GridDropout(p=1,  library="albumentations")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Add:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Add``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Add>`_ 

            value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Value to add to all pixels.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Add(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AddElementwise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AddElementwise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.AddElementwise>`_ 

            value( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the pixels.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AddElementwise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AddToHue:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AddToHue``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.AddToHue>`_ 

            value( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the hue of all pixels.
                This is expected to be in the range ``-255`` to ``+255`` and will
                automatically be projected to an angular representation using
                ``(hue/255) * (360/2)`` (OpenCV's hue representation is in the
                range ``[0, 180]`` instead of ``[0, 360]``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AddToHue(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AddToHueAndSaturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AddToHueAndSaturation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.AddToHueAndSaturation>`_ 

            value( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the hue *and* saturation of all pixels.
                It is expected to be in the range ``-255`` to ``+255``.


            value_hue( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the hue of all pixels.
                This is expected to be in the range ``-255`` to ``+255`` and will
                automatically be projected to an angular representation using
                ``(hue/255) * (360/2)`` (OpenCV's hue representation is in the
                range ``[0, 180]`` instead of ``[0, 360]``).
                Only this or `value` may be set, not both.


            value_saturation( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the saturation of all pixels.
                It is expected to be in the range ``-255`` to ``+255``.
                Only this or `value` may be set, not both.


            per_channel( bool or float, optional):
                Whether to sample per image only one value from `value` and use it for
                both hue and saturation (``False``) or to sample independently one
                value for hue and one for saturation (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AddToHueAndSaturation(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AddToSaturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AddToSaturation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.AddToSaturation>`_ 

            value( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Value to add to the saturation of all pixels.
                It is expected to be in the range ``-255`` to ``+255``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AddToSaturation(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AdditiveLaplaceNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AdditiveLaplaceNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.AdditiveLaplaceNoise>`_ 

            loc( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Mean of the laplace distribution that generates the noise.


            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Standard deviation of the laplace distribution that generates the noise.
                Must be ``>=0``. If ``0`` then only `loc` will be used.
                Recommended to be around ``255*0.05``.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AdditiveLaplaceNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AdditivePoissonNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AdditivePoissonNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.AdditivePoissonNoise>`_ 

            lam( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Lambda parameter of the poisson distribution. Must be ``>=0``.
                Recommended values are around ``0.0`` to ``10.0``.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AdditivePoissonNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AffineCv2:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AffineCv2``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.AffineCv2>`_ 

            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter or dict {"x": number/tuple/list/StochasticParameter, "y": number/tuple/list/StochasticParameter}, optional):
                Scaling factor to use, where ``1.0`` denotes "no change" and
                ``0.5`` is zoomed out to ``50`` percent of the original size.


            translate_percent( number or tuple of number or list of number or imgaug.parameters.StochasticParameter or dict {"x": number/tuple/list/StochasticParameter, "y": number/tuple/list/StochasticParameter}, optional):
                Translation as a fraction of the image height/width (x-translation,
                y-translation), where ``0`` denotes "no change" and ``0.5`` denotes
                "half of the axis size".


            translate_px( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or dict {"x": int/tuple/list/StochasticParameter, "y": int/tuple/list/StochasticParameter}, optional):
                Translation in pixels.


            rotate( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Rotation in degrees (**NOT** radians), i.e. expected value range is
                around ``[-360, 360]``. Rotation happens around the *center* of the
                image, not the top left corner as in some other frameworks.


            shear( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Shear in degrees (**NOT** radians), i.e. expected value range is
                around ``[-360, 360]``.


            order( int or list of int or str or list of str or imaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Allowed are:


            cval( number or tuple of number or list of number or imaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( int or str or list of str or list of int or imgaug.ALL or imgaug.parameters.StochasticParameter,):
                   optional
                Method to use when filling in newly created pixels.
                Same meaning as in OpenCV's border mode. Let ``abcdefgh`` be an image's
                content and ``|`` be an image boundary after which new pixels are
                filled in, then the valid modes and their behaviour are the following:



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AffineCv2(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AllChannelsCLAHE:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AllChannelsCLAHE``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.AllChannelsCLAHE>`_ 

            clip_limit( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See ``imgaug.augmenters.contrast.CLAHE``.


            tile_grid_size_px( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                See ``imgaug.augmenters.contrast.CLAHE``.


            tile_grid_size_px_min( int, optional):
                See ``imgaug.augmenters.contrast.CLAHE``.


            per_channel( bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AllChannelsCLAHE(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AllChannelsHistogramEqualization:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AllChannelsHistogramEqualization``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.AllChannelsHistogramEqualization>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AllChannelsHistogramEqualization(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AssertLambda:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AssertLambda``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.AssertLambda>`_ 

            func_images( None or callable, optional):
                The function to call for each batch of images.
                It must follow the form::


            func_heatmaps( None or callable, optional):
                The function to call for each batch of heatmaps.
                It must follow the form::


            func_segmentation_maps( None or callable, optional):
                The function to call for each batch of segmentation maps.
                It must follow the form::


            func_keypoints( None or callable, optional):
                The function to call for each batch of keypoints.
                It must follow the form::


            func_bounding_boxes( None or callable, optional):
                The function to call for each batch of bounding boxes.
                It must follow the form::


            func_polygons( None or callable, optional):
                The function to call for each batch of polygons.
                It must follow the form::


            func_line_strings( None or callable, optional):
                The function to call for each batch of line strings.
                It must follow the form::



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AssertLambda(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AssertShape:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AssertShape``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.AssertShape>`_ 

            shape( tuple):
                The expected shape, given as a ``tuple``. The number of entries in
                the ``tuple`` must match the number of dimensions, i.e. it must
                contain four entries for ``(N, H, W, C)``. If only a single entity
                is augmented, e.g. via
                :func:`~imgaug.augmenters.meta.Augmenter.augment_image`, then ``N`` is
                ``1`` in the input to this augmenter. Images that don't have
                a channel axis will automatically have one assigned, i.e. ``C`` is
                at least ``1``.
                For each component of the ``tuple`` one of the following datatypes
                may be used:


            check_images( bool, optional):
                Whether to validate input images via the given shape.


            check_heatmaps( bool, optional):
                Whether to validate input heatmaps via the given shape.
                The number of heatmaps will be verified as ``N``. For each
                :class:`~imgaug.augmentables.heatmaps.HeatmapsOnImage` instance
                its array's height and width will be verified as ``H`` and ``W``,
                but not the channel count.


            check_segmentation_maps( bool, optional):
                Whether to validate input segmentation maps via the given shape.
                The number of segmentation maps will be verified as ``N``. For each
                :class:`~imgaug.augmentables.segmaps.SegmentationMapOnImage` instance
                its array's height and width will be verified as ``H`` and ``W``,
                but not the channel count.


            check_keypoints( bool, optional):
                Whether to validate input keypoints via the given shape.
                This will check (a) the number of keypoints and (b) for each
                :class:`~imgaug.augmentables.kps.KeypointsOnImage` instance the
                ``.shape`` attribute, i.e. the shape of the corresponding image.


            check_bounding_boxes( bool, optional):
                Whether to validate input bounding boxes via the given shape.
                This will check (a) the number of bounding boxes and (b) for each
                :class:`~imgaug.augmentables.bbs.BoundingBoxesOnImage` instance the
                ``.shape`` attribute, i.e. the shape of the corresponding image.


            check_polygons( bool, optional):
                Whether to validate input polygons via the given shape.
                This will check (a) the number of polygons and (b) for each
                :class:`~imgaug.augmentables.polys.PolygonsOnImage` instance the
                ``.shape`` attribute, i.e. the shape of the corresponding image.


            check_line_strings( bool, optional):
                Whether to validate input line strings via the given shape.
                This will check (a) the number of line strings and (b) for each
                :class:`~imgaug.augmentables.lines.LineStringsOnImage` instance the
                ``.shape`` attribute, i.e. the shape of the corresponding image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AssertShape(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Augmenter:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Augmenter``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Augmenter>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Augmenter(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AveragePooling:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``AveragePooling``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pooling.html#imgaug.augmenters.pooling.AveragePooling>`_ 

            kernel_size( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                The kernel size of the pooling operation.


            keep_size( bool, optional):
                After pooling, the result image will usually have a different
                height/width compared to the original input image. If this
                parameter is set to True, then the pooled image will be resized
                to the input image's size, i.e. the augmenter's output shape is always
                identical to the input shape.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AveragePooling(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BilateralBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BilateralBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.BilateralBlur>`_ 

            d( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Diameter of each pixel neighborhood with value range ``[1 .. inf)``.
                High values for `d` lead to significantly worse performance. Values
                equal or less than ``10`` seem to be good. Use ``<5`` for real-time
                applications.


            sigma_color( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Filter sigma in the color space with value range ``[1, inf)``. A
                large value of the parameter means that farther colors within the
                pixel neighborhood (see `sigma_space`) will be mixed together,
                resulting in larger areas of semi-equal color.


            sigma_space( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Filter sigma in the coordinate space with value range ``[1, inf)``. A
                large value of the parameter means that farther pixels will influence
                each other as long as their colors are close enough (see
                `sigma_color`).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BilateralBlur(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlpha:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlpha``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlpha>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Opacity of the results of the foreground branch. Values close to
                ``0.0`` mean that the results from the background branch (see
                parameter `background`) make up most of the final image.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use the same factor for all channels (``False``)
                or to sample a new value for each channel (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as True, otherwise as False.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlpha(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaBoundingBoxes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaBoundingBoxes``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaBoundingBoxes>`_ 

            labels( None or str or list of str or imgaug.parameters.StochasticParameter):
                See :class:`~imgaug.augmenters.blend.BoundingBoxesMaskGen`.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            nb_sample_labels( None or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.BoundingBoxesMaskGen`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaBoundingBoxes(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaCheckerboard:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaCheckerboard``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaCheckerboard>`_ 

            nb_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of rows of the checkerboard.
                See :class:`~imgaug.augmenters.blend.CheckerboardMaskGen` for details.


            nb_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of columns of the checkerboard. Analogous to `nb_rows`.
                See :class:`~imgaug.augmenters.blend.CheckerboardMaskGen` for details.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaCheckerboard(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaElementwise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaElementwise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaElementwise>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Opacity of the results of the foreground branch. Values close to
                ``0.0`` mean that the results from the background branch (see
                parameter `background`) make up most of the final image.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            per_channel( bool or float, optional):
                Whether to use the same factor for all channels (``False``)
                or to sample a new value for each channel (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as True, otherwise as False.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaElementwise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaFrequencyNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaFrequencyNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaFrequencyNoise>`_ 

            exponent( number or tuple of number of list of number or imgaug.parameters.StochasticParameter, optional):
                Exponent to use when scaling in the frequency domain.
                Sane values are in the range ``-4`` (large blobs) to ``4`` (small
                patterns). To generate cloud-like structures, use roughly ``-2``.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            per_channel( bool or float, optional):
                Whether to use the same factor for all channels (``False``)
                or to sample a new value for each channel (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``, otherwise as ``False``.


            size_px_max( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                The noise is generated in a low resolution environment.
                This parameter defines the maximum size of that environment (in
                pixels). The environment is initialized at the same size as the input
                image and then downscaled, so that no side exceeds `size_px_max`
                (aspect ratio is kept).


            upscale_method( None or imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                After generating the noise maps in low resolution environments, they
                have to be upscaled to the input image size. This parameter controls
                the upscaling method.


            iterations( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                How often to repeat the simplex noise generation process per
                image.


            aggregation_method( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                The noise maps (from each iteration) are combined to one noise map
                using an aggregation process. This parameter defines the method used
                for that process. Valid methods are ``min``, ``max`` or ``avg``,
                where 'min' combines the noise maps by taking the (elementwise) minimum
                over all iteration's results, ``max`` the (elementwise) maximum and
                ``avg`` the (elementwise) average.


            sigmoid( bool or number, optional):
                Whether to apply a sigmoid function to the final noise maps, resulting
                in maps that have more extreme values (close to ``0.0`` or ``1.0``).


            sigmoid_thresh( None or number or tuple of number or imgaug.parameters.StochasticParameter, optional):
                Threshold of the sigmoid, when applied. Thresholds above zero
                (e.g. ``5.0``) will move the saddle point towards the right, leading to
                more values close to ``0.0``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaFrequencyNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaHorizontalLinearGradient:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaHorizontalLinearGradient``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaHorizontalLinearGradient>`_ 

            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            min_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.HorizontalLinearGradientMaskGen`.


            max_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.HorizontalLinearGradientMaskGen`.


            start_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.HorizontalLinearGradientMaskGen`.


            end_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.HorizontalLinearGradientMaskGen`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaHorizontalLinearGradient(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaMask:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaMask``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaMask>`_ 

            mask_generator( IBatchwiseMaskGenerator):
                A generator that will be queried per image to generate a mask.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaMask(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaRegularGrid:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaRegularGrid``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaRegularGrid>`_ 

            nb_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of rows of the checkerboard.
                See :class:`~imgaug.augmenters.blend.CheckerboardMaskGen` for details.


            nb_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of columns of the checkerboard. Analogous to `nb_rows`.
                See :class:`~imgaug.augmenters.blend.CheckerboardMaskGen` for details.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Alpha value of each cell.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaRegularGrid(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaSegMapClassIds:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaSegMapClassIds``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaSegMapClassIds>`_ 

            class_ids( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                See :class:`~imgaug.augmenters.blend.SegMapClassIdsMaskGen`.


            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            nb_sample_classes( None or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.SegMapClassIdsMaskGen`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaSegMapClassIds(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaSimplexNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaSimplexNoise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaSimplexNoise>`_ 

            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            per_channel( bool or float, optional):
                Whether to use the same factor for all channels (``False``)
                or to sample a new value for each channel (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``, otherwise as ``False``.


            size_px_max( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                The simplex noise is always generated in a low resolution environment.
                This parameter defines the maximum size of that environment (in
                pixels). The environment is initialized at the same size as the input
                image and then downscaled, so that no side exceeds `size_px_max`
                (aspect ratio is kept).


            upscale_method( None or imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                After generating the noise maps in low resolution environments, they
                have to be upscaled to the input image size. This parameter controls
                the upscaling method.


            iterations( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                How often to repeat the simplex noise generation process per image.


            aggregation_method( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                The noise maps (from each iteration) are combined to one noise map
                using an aggregation process. This parameter defines the method used
                for that process. Valid methods are ``min``, ``max`` or ``avg``,
                where ``min`` combines the noise maps by taking the (elementwise)
                minimum over all iteration's results, ``max`` the (elementwise)
                maximum and ``avg`` the (elementwise) average.


            sigmoid( bool or number, optional):
                Whether to apply a sigmoid function to the final noise maps, resulting
                in maps that have more extreme values (close to 0.0 or 1.0).


            sigmoid_thresh( None or number or tuple of number or imgaug.parameters.StochasticParameter, optional):
                Threshold of the sigmoid, when applied. Thresholds above zero
                (e.g. ``5.0``) will move the saddle point towards the right, leading
                to more values close to 0.0.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaSimplexNoise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaSomeColors:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaSomeColors``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaSomeColors>`_ 

            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            nb_bins( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.SomeColorsMaskGen`.


            smoothness( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.SomeColorsMaskGen`.


            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.SomeColorsMaskGen`.


            rotation_deg( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.SomeColorsMaskGen`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaSomeColors(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BlendAlphaVerticalLinearGradient:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BlendAlphaVerticalLinearGradient``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BlendAlphaVerticalLinearGradient>`_ 

            foreground( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the foreground branch.
                High alpha values will show this branch's results.


            background( None or imgaug.augmenters.meta.Augmenter or iterable of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) that make up the background branch.
                Low alpha values will show this branch's results.


            min_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.VerticalLinearGradientMaskGen`.


            max_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.VerticalLinearGradientMaskGen`.


            start_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.VerticalLinearGradientMaskGen`.


            end_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.blend.VerticalLinearGradientMaskGen`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BlendAlphaVerticalLinearGradient(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.BoundingBoxesMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``BoundingBoxesMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.BoundingBoxesMaskGen>`_ 

            labels( None or str or list of str or imgaug.parameters.StochasticParameter):
                Labels of bounding boxes to select for.


            nb_sample_labels( None or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of labels to sample (with replacement) per image.
                As sampling happens with replacement, fewer *unique* labels may be
                sampled.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.BoundingBoxesMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Canny:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Canny``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_edges.html#imgaug.augmenters.edges.Canny>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Blending factor to use in alpha blending.
                A value close to 1.0 means that only the edge image is visible.
                A value close to 0.0 means that only the original image is visible.
                A value close to 0.5 means that the images are merged according to
                `0.5*image + 0.5*edge_image`.
                If a sample from this parameter is 0, no action will be performed for
                the corresponding image.


            hysteresis_thresholds( number or tuple of number or list of number or imgaug.parameters.StochasticParameter or tuple of tuple of number or tuple of list of number or tuple of imgaug.parameters.StochasticParameter, optional):
                Min and max values to use in hysteresis thresholding.
                (This parameter seems to have not very much effect on the results.)
                Either a single parameter or a tuple of two parameters.
                If a single parameter is provided, the sampling happens once for all
                images with `(N,2)` samples being requested from the parameter,
                where each first value denotes the hysteresis minimum and each second
                the maximum.
                If a tuple of two parameters is provided, one sampling of `(N,)` values
                is independently performed per parameter (first parameter: hysteresis
                minimum, second: hysteresis maximum).


            sobel_kernel_size( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Kernel size of the sobel operator initially applied to each image.
                This corresponds to ``apertureSize`` in ``cv2.Canny()``.
                If a sample from this parameter is ``<=1``, no action will be performed
                for the corresponding image.
                The maximum for this parameter is ``7`` (inclusive). Higher values are
                not accepted by OpenCV.
                If an even value ``v`` is sampled, it is automatically changed to
                ``v-1``.


            colorizer( None or imgaug.augmenters.edges.IBinaryImageColorizer, optional):
                A strategy to convert binary edge images to color images.
                If this is ``None``, an instance of ``RandomColorBinaryImageColorizer``
                is created, which means that each edge image is converted into an
                ``uint8`` image, where edge and non-edge pixels each have a different
                color that was uniformly randomly sampled from the space of all
                ``uint8`` colors.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Canny(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Cartoon:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Cartoon``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_artistic.html#imgaug.augmenters.artistic.Cartoon>`_ 

            blur_ksize( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Median filter kernel size.
                See :func:`~imgaug.augmenters.artistic.stylize_cartoon` for details.


            segmentation_size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Mean-Shift segmentation size multiplier.
                See :func:`~imgaug.augmenters.artistic.stylize_cartoon` for details.


            saturation( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Saturation multiplier.
                See :func:`~imgaug.augmenters.artistic.stylize_cartoon` for details.


            edge_prevalence( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier for the prevalence of edges.
                See :func:`~imgaug.augmenters.artistic.stylize_cartoon` for details.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Cartoon(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCropToAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterCropToAspectRatio``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterCropToAspectRatio>`_ 

            aspect_ratio( number):
                See :func:`CropToAspectRatio.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCropToAspectRatio(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCropToFixedSize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CropToFixedSize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToFixedSize>`_ 

            width( int or None):
                Crop images down to this maximum width.
                If ``None``, image widths will not be altered.


            height( int or None):
                Crop images down to this maximum height.
                If ``None``, image heights will not be altered.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                 Sets the center point of the cropping, which determines how the
                 required cropping amounts are distributed to each side. For a
                 ``tuple`` ``(a, b)``, both ``a`` and ``b`` are expected to be in
                 range ``[0.0, 1.0]`` and describe the fraction of cropping applied
                 to the left/right (low/high values for ``a``) and the fraction
                 of cropping applied to the top/bottom (low/high values for ``b``).
                 A cropping position at ``(0.5, 0.5)`` would be the center of the
                 image and distribute the cropping equally over all sides. A cropping
                 position at ``(1.0, 0.0)`` would be the right-top and would apply
                 100% of the required cropping to the right and top sides of the image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCropToFixedSize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCropToMultiplesOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterCropToMultiplesOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterCropToMultiplesOf>`_ 

            width_multiple( int or None):
                See :func:`CropToMultiplesOf.__init__`.


            height_multiple( int or None):
                See :func:`CropToMultiplesOf.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCropToMultiplesOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCropToPowersOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterCropToPowersOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterCropToPowersOf>`_ 

            width_base( int or None):
                See :func:`CropToPowersOf.__init__`.


            height_base( int or None):
                See :func:`CropToPowersOf.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCropToPowersOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterCropToSquare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterCropToSquare``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterCropToSquare>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterCropToSquare(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterPadToAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterPadToAspectRatio``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterPadToAspectRatio>`_ 

            aspect_ratio( number):
                See :func:`PadToAspectRatio.__init__`.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToAspectRatio.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToAspectRatio.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterPadToAspectRatio(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterPadToFixedSize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToFixedSize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToFixedSize>`_ 

            width( int or None):
                Pad images up to this minimum width.
                If ``None``, image widths will not be altered.


            height( int or None):
                Pad images up to this minimum height.
                If ``None``, image heights will not be altered.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.CropAndPad.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.CropAndPad.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                Sets the center point of the padding, which determines how the
                required padding amounts are distributed to each side. For a ``tuple``
                ``(a, b)``, both ``a`` and ``b`` are expected to be in range
                ``[0.0, 1.0]`` and describe the fraction of padding applied to the
                left/right (low/high values for ``a``) and the fraction of padding
                applied to the top/bottom (low/high values for ``b``). A padding
                position at ``(0.5, 0.5)`` would be the center of the image and
                distribute the padding equally to all sides. A padding position at
                ``(0.0, 1.0)`` would be the left-bottom and would apply 100% of the
                required padding to the bottom and left sides of the image so that
                the bottom left corner becomes more and more the new image
                center (depending on how much is padded).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterPadToFixedSize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterPadToMultiplesOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterPadToMultiplesOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterPadToMultiplesOf>`_ 

            width_multiple( int or None):
                See :func:`PadToMultiplesOf.__init__`.


            height_multiple( int or None):
                See :func:`PadToMultiplesOf.__init__`.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToMultiplesOf.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToMultiplesOf.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterPadToMultiplesOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterPadToPowersOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterPadToPowersOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterPadToPowersOf>`_ 

            width_base( int or None):
                See :func:`PadToPowersOf.__init__`.


            height_base( int or None):
                See :func:`PadToPowersOf.__init__`.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToPowersOf.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToPowersOf.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterPadToPowersOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CenterPadToSquare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CenterPadToSquare``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CenterPadToSquare>`_ 

            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToAspectRatio.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToAspectRatio.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CenterPadToSquare(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ChangeColorTemperature:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ChangeColorTemperature``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.ChangeColorTemperature>`_ 

            kelvin( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Temperature in Kelvin. The temperatures of images will be modified to
                this value. Must be in the interval ``[1000, 40000]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ChangeColorTemperature(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ChangeColorspace:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ChangeColorspace``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.ChangeColorspace>`_ 

            to_colorspace( str or list of str or imgaug.parameters.StochasticParameter):
                The target colorspace.
                Allowed strings are: ``RGB``, ``BGR``, ``GRAY``, ``CIE``, ``YCrCb``,
                ``HSV``, ``HLS``, ``Lab``, ``Luv``.
                These are also accessible via
                ``imgaug.augmenters.color.CSPACE_<NAME>``,
                e.g. ``imgaug.augmenters.CSPACE_YCrCb``.


            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The alpha value of the new colorspace when overlayed over the
                old one. A value close to 1.0 means that mostly the new
                colorspace is visible. A value close to 0.0 means, that mostly the
                old image is visible.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ChangeColorspace(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CheckerboardMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CheckerboardMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.CheckerboardMaskGen>`_ 

            nb_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of rows of the checkerboard.


            nb_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of columns of the checkerboard. Analogous to `nb_rows`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CheckerboardMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ClipCBAsToImagePlanes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ClipCBAsToImagePlanes``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.ClipCBAsToImagePlanes>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ClipCBAsToImagePlanes(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CloudLayer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CloudLayer``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.CloudLayer>`_ 

            intensity_mean( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Mean intensity of the clouds (i.e. mean color).
                Recommended to be in the interval ``[190, 255]``.


            intensity_freq_exponent( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Exponent of the frequency noise used to add fine intensity to the
                mean intensity.
                Recommended to be in the interval ``[-2.5, -1.5]``.
                See :func:`~imgaug.parameters.FrequencyNoise.__init__` for details.


            intensity_coarse_scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Standard deviation of the gaussian distribution used to add more
                localized intensity to the mean intensity. Sampled in low resolution
                space, i.e. affects final intensity on a coarse level.
                Recommended to be in the interval ``(0, 10]``.


            alpha_min( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Minimum alpha when blending cloud noise with the image.
                High values will lead to clouds being "everywhere".
                Recommended to usually be at around ``0.0`` for clouds and ``>0`` for
                fog.


            alpha_multiplier( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Multiplier for the sampled alpha values. High values will lead to
                denser clouds wherever they are visible.
                Recommended to be in the interval ``[0.3, 1.0]``.
                Note that this parameter currently overlaps with `density_multiplier`,
                which is applied a bit later to the alpha mask.


            alpha_size_px_max( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Controls the image size at which the alpha mask is sampled.
                Lower values will lead to coarser alpha masks and hence larger
                clouds (and empty areas).
                See :func:`~imgaug.parameters.FrequencyNoise.__init__` for details.


            alpha_freq_exponent( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Exponent of the frequency noise used to sample the alpha mask.
                Similarly to `alpha_size_max_px`, lower values will lead to coarser
                alpha patterns.
                Recommended to be in the interval ``[-4.0, -1.5]``.
                See :func:`~imgaug.parameters.FrequencyNoise.__init__` for details.


            sparsity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Exponent applied late to the alpha mask. Lower values will lead to
                coarser cloud patterns, higher values to finer patterns.
                Recommended to be somewhere around ``1.0``.
                Do not deviate far from that value, otherwise the alpha mask might
                get weird patterns with sudden fall-offs to zero that look very
                unnatural.


            density_multiplier( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Late multiplier for the alpha mask, similar to `alpha_multiplier`.
                Set this higher to get "denser" clouds wherever they are visible.
                Recommended to be around ``[0.5, 1.5]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CloudLayer(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Clouds:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Clouds``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.Clouds>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Clouds(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CoarsePepper:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CoarsePepper``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.CoarsePepper>`_ 

            size_px( int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask in absolute pixel dimensions.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            size_percent( float or tuple of float or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask *in percent* of the input image.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).


            min_size( int, optional):
                Minimum size of the low resolution mask, both width and height. If
                `size_percent` or `size_px` leads to a lower value than this, `min_size`
                will be used instead. This should never have a value of less than 2,
                otherwise one may end up with a ``1x1`` low resolution mask, leading
                easily to the whole image being replaced.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CoarsePepper(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CoarseSalt:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CoarseSalt``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.CoarseSalt>`_ 

            size_px( int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask in absolute pixel dimensions.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            size_percent( float or tuple of float or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask *in percent* of the input image.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).


            min_size( int, optional):
                Minimum height and width of the low resolution mask. If
                `size_percent` or `size_px` leads to a lower value than this,
                `min_size` will be used instead. This should never have a value of
                less than ``2``, otherwise one may end up with a ``1x1`` low resolution
                mask, leading easily to the whole image being replaced.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CoarseSalt(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CoarseSaltAndPepper:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CoarseSaltAndPepper``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.CoarseSaltAndPepper>`_ 

            size_px( int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask in absolute pixel dimensions.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            size_percent( float or tuple of float or imgaug.parameters.StochasticParameter, optional):
                The size of the lower resolution image from which to sample the
                replacement mask *in percent* of the input image.
                Note that this means that *lower* values of this parameter lead to
                *larger* areas being replaced (as any pixel in the lower resolution
                image will correspond to a larger area at the original resolution).


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).


            min_size( int, optional):
                Minimum height and width of the low resolution mask. If
                `size_percent` or `size_px` leads to a lower value than this,
                `min_size` will be used instead. This should never have a value of
                less than ``2``, otherwise one may end up with a ``1x1`` low resolution
                mask, leading easily to the whole image being replaced.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CoarseSaltAndPepper(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Convolve:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Convolve``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_convolutional.html#imgaug.augmenters.convolutional.Convolve>`_ 

            matrix( None or (H, W) ndarray or imgaug.parameters.StochasticParameter or callable, optional):
                The weight matrix of the convolution kernel to apply.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Convolve(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropToAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CropToAspectRatio``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToAspectRatio>`_ 

            aspect_ratio( number):
                The desired aspect ratio, given as ``width/height``. E.g. a ratio
                of ``2.0`` denotes an image that is twice as wide as it is high.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`CropToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropToAspectRatio(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropToMultiplesOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CropToMultiplesOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToMultiplesOf>`_ 

            width_multiple( int or None):
                Multiple for the width. Images will be cropped down until their
                width is a multiple of this value.
                If ``None``, image widths will not be altered.


            height_multiple( int or None):
                Multiple for the height. Images will be cropped down until their
                height is a multiple of this value.
                If ``None``, image heights will not be altered.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`CropToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropToMultiplesOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropToPowersOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CropToPowersOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToPowersOf>`_ 

            width_base( int or None):
                Base for the width. Images will be cropped down until their
                width fulfills ``width' = width_base ^ E`` with ``E`` being any
                natural number.
                If ``None``, image widths will not be altered.


            height_base( int or None):
                Base for the height. Images will be cropped down until their
                height fulfills ``height' = height_base ^ E`` with ``E`` being any
                natural number.
                If ``None``, image heights will not be altered.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`CropToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropToPowersOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.CropToSquare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``CropToSquare``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.CropToSquare>`_ 

            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`CropToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.CropToSquare(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.DirectedEdgeDetect:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``DirectedEdgeDetect``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_convolutional.html#imgaug.augmenters.convolutional.DirectedEdgeDetect>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Blending factor of the edge image. At ``0.0``, only the original
                image is visible, at ``1.0`` only the edge image is visible.


            direction( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Angle (in degrees) of edges to pronounce, where ``0`` represents
                ``0`` degrees and ``1.0`` represents 360 degrees (both clockwise,
                starting at the top). Default value is ``(0.0, 1.0)``, i.e. pick a
                random angle per image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.DirectedEdgeDetect(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Dropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Dropout``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Dropout>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Dropout(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Dropout2d:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Dropout2d``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Dropout2d>`_ 

            nb_keep_channels( int):
                Minimum number of channels to keep unaltered in all images.
                E.g. a value of ``1`` means that at least one channel in every image
                will not be dropped, even if ``p=1.0``. Set to ``0`` to allow dropping
                all channels.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Dropout2d(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.DropoutPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``DropoutPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.DropoutPointsSampler>`_ 

            other_points_sampler( IPointsSampler):
                Another point sampler that is queried to generate a list of points.
                The dropout operation will be applied to that list.


            p_drop( number or tuple of number or imgaug.parameters.StochasticParameter):
                The probability that a coordinate will be removed from the list
                of all sampled coordinates. A value of ``1.0`` would mean that (on
                average) ``100`` percent of all coordinates will be dropped,
                while ``0.0`` denotes ``0`` percent. Note that this sampler will
                always ensure that at least one coordinate is left after the dropout
                operation, i.e. even ``1.0`` will only drop all *except one*
                coordinate.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.DropoutPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EdgeDetect:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``EdgeDetect``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_convolutional.html#imgaug.augmenters.convolutional.EdgeDetect>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Blending factor of the edge image. At ``0.0``, only the original
                image is visible, at ``1.0`` only the edge image is visible.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.EdgeDetect(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FastSnowyLandscape:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FastSnowyLandscape``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.FastSnowyLandscape>`_ 

            lightness_threshold( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                All pixels with lightness in HLS colorspace that is below this value
                will have their lightness increased by `lightness_multiplier`.


            lightness_multiplier( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier for pixel's lightness value in HLS colorspace.
                Affects all pixels selected via `lightness_threshold`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FastSnowyLandscape(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.GammaContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``GammaContrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.GammaContrast>`_ 

            gamma( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Exponent for the contrast adjustment. Higher values darken the image.


            per_channel( bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.GammaContrast(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.HistogramEqualization:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``HistogramEqualization``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.HistogramEqualization>`_ 

            to_colorspace( {"Lab", "HLS", "HSV"}, optional):
                Colorspace in which to perform Histogram Equalization. For ``Lab``,
                the equalization will only be applied to the first channel (``L``),
                for ``HLS`` to the second (``L``) and for ``HSV`` to the third (``V``).
                To apply histogram equalization to all channels of an input image
                (without colorspace conversion), see
                ``imgaug.augmenters.contrast.AllChannelsHistogramEqualization``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.HistogramEqualization(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.HorizontalLinearGradientMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``HorizontalLinearGradientMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.HorizontalLinearGradientMaskGen>`_ 

            min_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Minimum value that the mask will have up to the start point of the
                linear gradient.
                Note that `min_value` is allowed to be larger than `max_value`,
                in which case the gradient will start at the (higher) `min_value`
                and decrease towards the (lower) `max_value`.


            max_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Maximum value that the mask will have at the end of the
                linear gradient.


            start_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Position on the x-axis where the linear gradient starts, given as a
                fraction of the axis size. Interval is ``[0.0, 1.0]``, where ``0.0``
                is at the left of the image.
                If ``end_at < start_at`` the gradient will be inverted.


            end_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Position on the x-axis where the linear gradient ends, given as a
                fraction of the axis size. Interval is ``[0.0, 1.0]``, where ``0.0``
                is at the right of the image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.HorizontalLinearGradientMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.IBatchwiseMaskGenerator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``IBatchwiseMaskGenerator``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.IBatchwiseMaskGenerator>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.IBatchwiseMaskGenerator(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.IBinaryImageColorizer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``IBinaryImageColorizer``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_edges.html#imgaug.augmenters.edges.IBinaryImageColorizer>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.IBinaryImageColorizer(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.IPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``IPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.IPointsSampler>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.IPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Identity:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Identity``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Identity>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Identity(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.InvertMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``InvertMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.InvertMaskGen>`_ 

            child( IBatchwiseMaskGenerator):
                The other mask generator to invert.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.InvertMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Jigsaw:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Jigsaw``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.Jigsaw>`_ 

            nb_rows( int or list of int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                How many rows the jigsaw pattern should have.


            nb_cols( int or list of int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                How many cols the jigsaw pattern should have.


            max_steps( int or list of int or tuple of int or imgaug.parameters.StochasticParameter, optional):
                How many steps each jigsaw cell may be moved.


            allow_pad( bool, optional):
                Whether to allow automatically padding images until they are evenly
                divisible by ``nb_rows`` and ``nb_cols``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Jigsaw(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.KMeansColorQuantization:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``KMeansColorQuantization``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.KMeansColorQuantization>`_ 

            n_colors( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Target number of colors in the generated output image.
                This corresponds to the number of clusters in k-Means, i.e. ``k``.
                Sampled values below ``2`` will always be clipped to ``2``.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( int or None, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.KMeansColorQuantization(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.KeepSizeByResize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``KeepSizeByResize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.KeepSizeByResize>`_ 

            children( Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to images. These augmenters may change
                the image size.


            interpolation( KeepSizeByResize.NO_RESIZE or {'nearest', 'linear', 'area', 'cubic'} or {cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC} or list of str or list of int or StochasticParameter, optional):
                The interpolation mode to use when resizing images.
                Can take any value that :func:`~imgaug.imgaug.imresize_single_image`
                accepts, e.g. ``cubic``.


            interpolation_heatmaps( KeepSizeByResize.SAME_AS_IMAGES or KeepSizeByResize.NO_RESIZE or {'nearest', 'linear', 'area', 'cubic'} or {cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC} or list of str or list of int or StochasticParameter, optional):
                The interpolation mode to use when resizing heatmaps.
                Meaning and valid values are similar to `interpolation`. This
                parameter may also take the value ``KeepSizeByResize.SAME_AS_IMAGES``,
                which will lead to copying the interpolation modes used for the
                corresponding images. The value may also be returned on a per-image
                basis if `interpolation_heatmaps` is provided as a
                ``StochasticParameter`` or may be one possible value if it is
                provided as a ``list`` of ``str``.


            interpolation_segmaps( KeepSizeByResize.SAME_AS_IMAGES or KeepSizeByResize.NO_RESIZE or {'nearest', 'linear', 'area', 'cubic'} or {cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_AREA, cv2.INTER_CUBIC} or list of str or list of int or StochasticParameter, optional):
                The interpolation mode to use when resizing segmentation maps.
                Similar to `interpolation_heatmaps`.
                **Note**: For segmentation maps, only ``NO_RESIZE`` or nearest
                neighbour interpolation (i.e. ``nearest``) make sense in the vast
                majority of all cases.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.KeepSizeByResize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.LinearContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``LinearContrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.LinearContrast>`_ 

            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier to linearly pronounce (``>1.0``), dampen (``0.0`` to
                ``1.0``) or invert (``<0.0``) the difference between each pixel value
                and the dtype's center value, e.g. ``127`` for ``uint8``.


            per_channel( bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.LinearContrast(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.LogContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``LogContrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.LogContrast>`_ 

            gain( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier for the logarithm result. Values around ``1.0`` lead to a
                contrast-adjusted images. Values above ``1.0`` quickly lead to
                partially broken images due to exceeding the datatype's value range.


            per_channel( bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.LogContrast(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MaxPooling:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MaxPooling``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pooling.html#imgaug.augmenters.pooling.MaxPooling>`_ 

            kernel_size( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                The kernel size of the pooling operation.


            keep_size( bool, optional):
                After pooling, the result image will usually have a different
                height/width compared to the original input image. If this
                parameter is set to True, then the pooled image will be resized
                to the input image's size, i.e. the augmenter's output shape is always
                identical to the input shape.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MaxPooling(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MeanShiftBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MeanShiftBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blur.html#imgaug.augmenters.blur.MeanShiftBlur>`_ 

            spatial_radius( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Spatial radius for pixels that are assumed to be similar.


            color_radius( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Color radius for pixels that are assumed to be similar.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MeanShiftBlur(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MedianPooling:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MedianPooling``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pooling.html#imgaug.augmenters.pooling.MedianPooling>`_ 

            kernel_size( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                The kernel size of the pooling operation.


            keep_size( bool, optional):
                After pooling, the result image will usually have a different
                height/width compared to the original input image. If this
                parameter is set to True, then the pooled image will be resized
                to the input image's size, i.e. the augmenter's output shape is always
                identical to the input shape.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MedianPooling(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MinPooling:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MinPooling``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pooling.html#imgaug.augmenters.pooling.MinPooling>`_ 

            kernel_size( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or tuple of tuple of int or tuple of list of int or tuple of imgaug.parameters.StochasticParameter, optional):
                The kernel size of the pooling operation.


            keep_size( bool, optional):
                After pooling, the result image will usually have a different
                height/width compared to the original input image. If this
                parameter is set to True, then the pooled image will be resized
                to the input image's size, i.e. the augmenter's output shape is always
                identical to the input shape.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MinPooling(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Multiply:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Multiply``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Multiply>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The value with which to multiply the pixel values in each image.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Multiply(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MultiplyAndAddToBrightness:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MultiplyAndAddToBrightness``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.MultiplyAndAddToBrightness>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.airthmetic.Multiply`.


            add( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.airthmetic.Add`.


            to_colorspace( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :class:`~imgaug.augmenters.color.WithBrightnessChannels`.


            random_order( bool, optional):
                Whether to apply the add and multiply operations in random
                order (``True``). If ``False``, this augmenter will always first
                multiply and then add.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MultiplyAndAddToBrightness(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MultiplyElementwise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MultiplyElementwise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.MultiplyElementwise>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                The value with which to multiply pixel values in the image.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MultiplyElementwise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MultiplyHue:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MultiplyHue``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.MultiplyHue>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier with which to multiply all hue values.
                This is expected to be in the range ``-10.0`` to ``+10.0`` and will
                automatically be projected to an angular representation using
                ``(hue/255) * (360/2)`` (OpenCV's hue representation is in the
                range ``[0, 180]`` instead of ``[0, 360]``).
                Only this or `mul` may be set, not both.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MultiplyHue(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MultiplyHueAndSaturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``MultiplyHueAndSaturation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.MultiplyHueAndSaturation>`_ 

            mul( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier with which to multiply all hue *and* saturation values of
                all pixels.
                It is expected to be in the range ``-10.0`` to ``+10.0``.
                Note that values of ``0.0`` or lower will remove all saturation.


            mul_hue( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier with which to multiply all hue values.
                This is expected to be in the range ``-10.0`` to ``+10.0`` and will
                automatically be projected to an angular representation using
                ``(hue/255) * (360/2)`` (OpenCV's hue representation is in the
                range ``[0, 180]`` instead of ``[0, 360]``).
                Only this or `mul` may be set, not both.


            mul_saturation( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier with which to multiply all saturation values.
                It is expected to be in the range ``0.0`` to ``+10.0``.
                Only this or `mul` may be set, not both.


            per_channel( bool or float, optional):
                Whether to sample per image only one value from `mul` and use it for
                both hue and saturation (``False``) or to sample independently one
                value for hue and one for saturation (``True``).
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.MultiplyHueAndSaturation(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OneOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``OneOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.OneOf>`_ 

            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter):
                The choices of augmenters to apply.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.OneOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadToAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToAspectRatio``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToAspectRatio>`_ 

            aspect_ratio( number):
                The desired aspect ratio, given as ``width/height``. E.g. a ratio
                of ``2.0`` denotes an image that is twice as wide as it is high.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`PadToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadToAspectRatio(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadToFixedSize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToFixedSize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToFixedSize>`_ 

            width( int or None):
                Pad images up to this minimum width.
                If ``None``, image widths will not be altered.


            height( int or None):
                Pad images up to this minimum height.
                If ``None``, image heights will not be altered.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.CropAndPad.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.CropAndPad.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                Sets the center point of the padding, which determines how the
                required padding amounts are distributed to each side. For a ``tuple``
                ``(a, b)``, both ``a`` and ``b`` are expected to be in range
                ``[0.0, 1.0]`` and describe the fraction of padding applied to the
                left/right (low/high values for ``a``) and the fraction of padding
                applied to the top/bottom (low/high values for ``b``). A padding
                position at ``(0.5, 0.5)`` would be the center of the image and
                distribute the padding equally to all sides. A padding position at
                ``(0.0, 1.0)`` would be the left-bottom and would apply 100% of the
                required padding to the bottom and left sides of the image so that
                the bottom left corner becomes more and more the new image
                center (depending on how much is padded).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadToFixedSize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadToMultiplesOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToMultiplesOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToMultiplesOf>`_ 

            width_multiple( int or None):
                Multiple for the width. Images will be padded until their
                width is a multiple of this value.
                If ``None``, image widths will not be altered.


            height_multiple( int or None):
                Multiple for the height. Images will be padded until their
                height is a multiple of this value.
                If ``None``, image heights will not be altered.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`PadToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadToMultiplesOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadToPowersOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToPowersOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToPowersOf>`_ 

            width_base( int or None):
                Base for the width. Images will be padded down until their
                width fulfills ``width' = width_base ^ E`` with ``E`` being any
                natural number.
                If ``None``, image widths will not be altered.


            height_base( int or None):
                Base for the height. Images will be padded until their
                height fulfills ``height' = height_base ^ E`` with ``E`` being any
                natural number.
                If ``None``, image heights will not be altered.


            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`PadToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadToPowersOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadToSquare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``PadToSquare``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_size.html#imgaug.augmenters.size.PadToSquare>`_ 

            pad_mode( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            pad_cval( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                See :func:`~imgaug.augmenters.size.PadToFixedSize.__init__`.


            position( {'uniform', 'normal', 'center', 'left-top', 'left-center', 'left-bottom', 'center-top', 'center-center', 'center-bottom', 'right-top', 'right-center', 'right-bottom'} or tuple of float or StochasticParameter or tuple of StochasticParameter, optional):
                See :func:`PadToFixedSize.__init__`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PadToSquare(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Pepper:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Pepper``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Pepper>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Pepper(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Rain:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Rain``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.Rain>`_ 

            drop_size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                See :class:`~imgaug.augmenters.weather.RainLayer`.


            speed( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                See :class:`~imgaug.augmenters.weather.RainLayer`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Rain(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RainLayer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RainLayer``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.RainLayer>`_ 

            density( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            density_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            drop_size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as `flake_size` in
                :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            drop_size_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as `flake_size_uniformity` in
                :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            angle( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            speed( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            blur_sigma_fraction( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.


            blur_sigma_limits( tuple of float, optional):
                Same as in :class:`~imgaug.augmenters.weather.SnowflakesLayer`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RainLayer(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandAugment:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RandAugment``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_collections.html#imgaug.augmenters.collections.RandAugment>`_ 

            n( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or None, optional):
                Parameter ``N`` in the paper, i.e. number of transformations to apply.
                The paper suggests ``N=2`` for ImageNet.
                See also parameter ``n`` i


            m( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or None, optional):
                Parameter ``M`` in the paper, i.e. magnitude/severity/strength of the
                applied transformations in interval ``[0 .. 30]`` with ``M=0`` being
                the weakest. The paper suggests for ImageNet ``M=9`` in case of
                ResNet-50 and ``M=28`` in case of EfficientNet-B7.
                This implementation uses a default value of ``(6, 12)``, i.e. the
                value is uniformly sampled per image from the interval ``[6 .. 12]``.
                This ensures greater diversity of transformations than using a single
                fixed value.


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                See parameter `fillcolor` in
                :class:`~imgaug.augmenters.pillike.Affine` for details.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandAugment(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomColorsBinaryImageColorizer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RandomColorsBinaryImageColorizer``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_edges.html#imgaug.augmenters.edges.RandomColorsBinaryImageColorizer>`_ 

            color_true( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Color of the foreground, i.e. all pixels in binary images that are
                ``True``. This parameter will be queried once per image to
                generate ``(3,)`` samples denoting the color. (Note that even for
                grayscale images three values will be sampled and converted to
                grayscale according to ``0.299*R + 0.587*G + 0.114*B``. This is the
                same equation that is also used by OpenCV.)


            color_false( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Analogous to `color_true`, but denotes the color for all pixels that
                are ``False`` in the binary input image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomColorsBinaryImageColorizer(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RegularGridMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RegularGridMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.RegularGridMaskGen>`_ 

            nb_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of rows of the regular grid.


            nb_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Number of columns of the checkerboard. Analogous to `nb_rows`.


            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Alpha value of each cell.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RegularGridMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RegularGridPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RegularGridPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RegularGridPointsSampler>`_ 

            n_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of rows of coordinates to place on each image, i.e. the number
                of coordinates on the y-axis. Note that for each image, the sampled
                value is clipped to the interval ``[1..H]``, where ``H`` is the image
                height.


            n_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of columns of coordinates to place on each image, i.e. the
                number of coordinates on the x-axis. Note that for each image, the
                sampled value is clipped to the interval ``[1..W]``, where ``W`` is
                the image width.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RegularGridPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RegularGridVoronoi:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RegularGridVoronoi``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RegularGridVoronoi>`_ 

            n_rows( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of rows of coordinates to place on each image, i.e. the number
                of coordinates on the y-axis. Note that for each image, the sampled
                value is clipped to the interval ``[1..H]``, where ``H`` is the image
                height.


            n_cols( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of columns of coordinates to place on each image, i.e. the
                number of coordinates on the x-axis. Note that for each image, the
                sampled value is clipped to the interval ``[1..W]``, where ``W`` is
                the image width.


            p_drop_points( number or tuple of number or imgaug.parameters.StochasticParameter, optional):
                The probability that a coordinate will be removed from the list
                of all sampled coordinates. A value of ``1.0`` would mean that (on
                average) ``100`` percent of all coordinates will be dropped,
                while ``0.0`` denotes ``0`` percent. Note that this sampler will
                always ensure that at least one coordinate is left after the dropout
                operation, i.e. even ``1.0`` will only drop all *except one*
                coordinate.


            p_replace( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Defines for any segment the probability that the pixels within that
                segment are replaced by their average color (otherwise, the pixels
                are not changed).
                Examples:


            max_size( int or None, optional):
                Maximum image size at which the augmentation is performed.
                If the width or height of an image exceeds this value, it will be
                downscaled before the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the process. The final output image has the
                same size as the input image. Note that in case `p_replace` is below
                ``1.0``, the down-/upscaling will affect the not-replaced pixels too.
                Use ``None`` to apply no down-/upscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RegularGridVoronoi(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RelativeRegularGridPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RelativeRegularGridPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RelativeRegularGridPointsSampler>`_ 

            n_rows_frac( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Relative number of coordinates to place on the y-axis. For a value
                ``y`` and image height ``H`` the number of actually placed coordinates
                (i.e. computed rows) is given by ``int(round(y*H))``.
                Note that for each image, the number of coordinates is clipped to the
                interval ``[1,H]``, where ``H`` is the image height.


            n_cols_frac( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Relative number of coordinates to place on the x-axis. For a value
                ``x`` and image height ``W`` the number of actually placed coordinates
                (i.e. computed columns) is given by ``int(round(x*W))``.
                Note that for each image, the number of coordinates is clipped to the
                interval ``[1,W]``, where ``W`` is the image width.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RelativeRegularGridPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RelativeRegularGridVoronoi:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RelativeRegularGridVoronoi``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.RelativeRegularGridVoronoi>`_ 

            n_rows_frac( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Relative number of coordinates to place on the y-axis. For a value
                ``y`` and image height ``H`` the number of actually placed coordinates
                (i.e. computed rows) is given by ``int(round(y*H))``.
                Note that for each image, the number of coordinates is clipped to the
                interval ``[1,H]``, where ``H`` is the image height.


            n_cols_frac( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Relative number of coordinates to place on the x-axis. For a value
                ``x`` and image height ``W`` the number of actually placed coordinates
                (i.e. computed columns) is given by ``int(round(x*W))``.
                Note that for each image, the number of coordinates is clipped to the
                interval ``[1,W]``, where ``W`` is the image width.


            p_drop_points( number or tuple of number or imgaug.parameters.StochasticParameter, optional):
                The probability that a coordinate will be removed from the list
                of all sampled coordinates. A value of ``1.0`` would mean that (on
                average) ``100`` percent of all coordinates will be dropped,
                while ``0.0`` denotes ``0`` percent. Note that this sampler will
                always ensure that at least one coordinate is left after the dropout
                operation, i.e. even ``1.0`` will only drop all *except one*
                coordinate.


            p_replace( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Defines for any segment the probability that the pixels within that
                segment are replaced by their average color (otherwise, the pixels
                are not changed).
                Examples:


            max_size( int or None, optional):
                Maximum image size at which the augmentation is performed.
                If the width or height of an image exceeds this value, it will be
                downscaled before the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the process. The final output image has the
                same size as the input image. Note that in case `p_replace` is below
                ``1.0``, the down-/upscaling will affect the not-replaced pixels too.
                Use ``None`` to apply no down-/upscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RelativeRegularGridVoronoi(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RemoveCBAsByOutOfImageFraction:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RemoveCBAsByOutOfImageFraction``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.RemoveCBAsByOutOfImageFraction>`_ 

            fraction( number):
                Remove any augmentable for which ``fraction_{actual} >= fraction``,
                where ``fraction_{actual}`` denotes the estimated out of image
                fraction.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RemoveCBAsByOutOfImageFraction(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RemoveSaturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``RemoveSaturation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.RemoveSaturation>`_ 

            mul( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                *Inverse* multiplier to use for the saturation values.
                High values denote stronger color removal. E.g. ``1.0`` will remove
                all saturation, ``0.0`` will remove nothing.
                Expected value range is ``[0.0, 1.0]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RemoveSaturation(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ReplaceElementwise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ReplaceElementwise``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.ReplaceElementwise>`_ 

            mask( float or tuple of float or list of float or imgaug.parameters.StochasticParameter):
                Mask that indicates the pixels that are supposed to be replaced.
                The mask will be binarized using a threshold of ``0.5``. A value
                of ``1`` then indicates a pixel that is supposed to be replaced.


            replacement( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                The replacement to use at all locations that are marked as ``1`` in
                the mask.


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ReplaceElementwise(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Rot90:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Rot90``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.Rot90>`_ 

            k( int or list of int or tuple of int or imaug.ALL or imgaug.parameters.StochasticParameter, optional):
                How often to rotate clockwise by 90 degrees.


            keep_size( bool, optional):
                After rotation by an odd-valued `k` (e.g. 1 or 3), the resulting image
                may have a different height/width than the original image.
                If this parameter is set to ``True``, then the rotated
                image will be resized to the input image's size. Note that this might
                also cause the augmented image to look distorted.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Rot90(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Salt:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Salt``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.Salt>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Salt(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SaltAndPepper:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SaltAndPepper``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.SaltAndPepper>`_ 

            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use (imagewise) the same sample(s) for all
                channels (``False``) or to sample value(s) for each channel (``True``).
                Setting this to ``True`` will therefore lead to different
                transformations per image *and* channel, otherwise only per image.
                If this value is a float ``p``, then for ``p`` percent of all images
                `per_channel` will be treated as ``True``.
                If it is a ``StochasticParameter`` it is expected to produce samples
                with values between ``0.0`` and ``1.0``, where values ``>0.5`` will
                lead to per-channel behaviour (i.e. same as ``True``).



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SaltAndPepper(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SaveDebugImageEveryNBatches:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SaveDebugImageEveryNBatches``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_debug.html#imgaug.augmenters.debug.SaveDebugImageEveryNBatches>`_ 

            destination( str or _IImageDestination):
                Path to a folder. The saved images will follow a filename pattern
                of ``batch_<batch_id>.png``. The latest image will additionally be
                saved to ``latest.png``.


            interval( int):
                Interval in batches. If set to ``N``, every ``N`` th batch an
                image will be generated and saved, starting with the first observed
                batch.
                Note that the augmenter only counts batches that it sees. If it is
                executed conditionally or re-instantiated, it may not see all batches
                or the counter may be wrong in other ways.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SaveDebugImageEveryNBatches(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ScaleX:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ScaleX``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ScaleX>`_ 

            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``scale`` in :class:`Affine`, except that this scale
                value only affects the x-axis. No dictionary input is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ScaleX(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ScaleY:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ScaleY``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ScaleY>`_ 

            scale( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``scale`` in :class:`Affine`, except that this scale
                value only affects the y-axis. No dictionary input is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ScaleY(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SegMapClassIdsMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SegMapClassIdsMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.SegMapClassIdsMaskGen>`_ 

            class_ids( int or tuple of int or list of int or imgaug.parameters.StochasticParameter):
                Segmentation map classes to mark in the produced mask.


            nb_sample_classes( None or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of class ids to sample (with replacement) per segmentation map.
                As sampling happens with replacement, fewer *unique* class ids may be
                sampled.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SegMapClassIdsMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Sequential:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Sequential``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Sequential>`_ 

            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                The augmenters to apply to images.


            random_order( bool, optional):
                Whether to apply the child augmenters in random order.
                If ``True``, the order will be randomly sampled once per batch.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Sequential(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ShearX:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ShearX``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ShearX>`_ 

            shear( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``shear`` in :class:`Affine`, except that this shear
                value only affects the x-axis. No dictionary input is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ShearX(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ShearY:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``ShearY``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.ShearY>`_ 

            shear( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``shear`` in :class:`Affine`, except that this shear
                value only affects the y-axis. No dictionary input is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ShearY(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SigmoidContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SigmoidContrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_contrast.html#imgaug.augmenters.contrast.SigmoidContrast>`_ 

            gain( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Multiplier for the sigmoid function's output.
                Higher values lead to quicker changes from dark to light pixels.


            cutoff( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Cutoff that shifts the sigmoid function in horizontal direction.
                Higher values mean that the switch from dark to light pixels happens
                later, i.e. the pixels will remain darker.


            per_channel( bool or float, optional):
                Whether to use the same value for all channels (``False``) or to
                sample a new value for each channel (``True``). If this value is a
                float ``p``, then for ``p`` percent of all images `per_channel` will
                be treated as ``True``, otherwise as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SigmoidContrast(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Snowflakes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Snowflakes``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.Snowflakes>`_ 

            density( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Density of the snowflake layer, as a probability of each pixel in
                low resolution space to be a snowflake.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be in the interval ``[0.01, 0.075]``.


            density_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Size uniformity of the snowflakes. Higher values denote more
                similarly sized snowflakes.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be around ``0.5``.


            flake_size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Size of the snowflakes. This parameter controls the resolution at
                which snowflakes are sampled. Higher values mean that the resolution
                is closer to the input image's resolution and hence each sampled
                snowflake will be smaller (because of the smaller pixel size).


            flake_size_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Controls the size uniformity of the snowflakes. Higher values mean
                that the snowflakes are more similarly sized.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be around ``0.5``.


            angle( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Angle in degrees of motion blur applied to the snowflakes, where
                ``0.0`` is motion blur that points straight upwards.
                Recommended to be in the interval ``[-30, 30]``.
                See also :func:`~imgaug.augmenters.blur.MotionBlur.__init__`.


            speed( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Perceived falling speed of the snowflakes. This parameter controls the
                motion blur's kernel size. It follows roughly the form
                ``kernel_size = image_size * speed``. Hence, values around ``1.0``
                denote that the motion blur should "stretch" each snowflake over
                the whole image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Snowflakes(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SnowflakesLayer:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SnowflakesLayer``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_weather.html#imgaug.augmenters.weather.SnowflakesLayer>`_ 

            density( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Density of the snowflake layer, as a probability of each pixel in
                low resolution space to be a snowflake.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be in the interval ``[0.01, 0.075]``.


            density_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Size uniformity of the snowflakes. Higher values denote more
                similarly sized snowflakes.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be around ``0.5``.


            flake_size( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Size of the snowflakes. This parameter controls the resolution at
                which snowflakes are sampled. Higher values mean that the resolution
                is closer to the input image's resolution and hence each sampled
                snowflake will be smaller (because of the smaller pixel size).


            flake_size_uniformity( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Controls the size uniformity of the snowflakes. Higher values mean
                that the snowflakes are more similarly sized.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be around ``0.5``.


            angle( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Angle in degrees of motion blur applied to the snowflakes, where
                ``0.0`` is motion blur that points straight upwards.
                Recommended to be in the interval ``[-30, 30]``.
                See also :func:`~imgaug.augmenters.blur.MotionBlur.__init__`.


            speed( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Perceived falling speed of the snowflakes. This parameter controls the
                motion blur's kernel size. It follows roughly the form
                ``kernel_size = image_size * speed``. Hence, values around ``1.0``
                denote that the motion blur should "stretch" each snowflake over the
                whole image.


            blur_sigma_fraction( number or tuple of number or list of number or imgaug.parameters.StochasticParameter):
                Standard deviation (as a fraction of the image size) of gaussian blur
                applied to the snowflakes.
                Valid values are in the interval ``[0.0, 1.0]``.
                Recommended to be in the interval ``[0.0001, 0.001]``. May still
                require tinkering based on image size.


            blur_sigma_limits( tuple of float, optional):
                Controls allowed min and max values of `blur_sigma_fraction`
                after(!) multiplication with the image size. First value is the
                minimum, second value is the maximum. Values outside of that range
                will be clipped to be within that range. This prevents extreme
                values for very small or large images.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SnowflakesLayer(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SomeColorsMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SomeColorsMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.SomeColorsMaskGen>`_ 

            nb_bins( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bins. For ``B`` bins, each bin denotes roughly ``360/B``
                degrees of colors in the hue channel. Lower values lead to a coarser
                selection of colors. Expected value range is ``[2, 256]``.


            smoothness( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Strength of the 1D gaussian kernel applied to the sampled binwise
                alpha values. Larger values will lead to more similar grayscaling of
                neighbouring colors. Expected value range is ``[0.0, 1.0]``.


            alpha( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Parameter to sample binwise alpha blending factors from. Expected
                value range is ``[0.0, 1.0]``.  Note that the alpha values will be
                smoothed between neighbouring bins. Hence, it is usually a good idea
                to set this so that the probability distribution peaks are around
                ``0.0`` and ``1.0``, e.g. via a list ``[0.0, 1.0]`` or a ``Beta``
                distribution.
                It is not recommended to set this to a deterministic value, otherwise
                all bins and hence all pixels in the generated mask will have the
                same value.


            rotation_deg( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Rotiational shift of each bin as a fraction of ``360`` degrees.
                E.g. ``0.0`` will not shift any bins, while a value of ``0.5`` will
                shift by around ``180`` degrees. This shift is mainly used so that
                the ``0th`` bin does not always start at ``0deg``. Expected value
                range is ``[-360, 360]``. This parameter can usually be kept at the
                default value.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SomeColorsMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SomeOf:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SomeOf``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.SomeOf>`_ 

            n( int or tuple of int or list of int or imgaug.parameters.StochasticParameter or None, optional):
                Count of augmenters to apply.


            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                The augmenters to apply to images.
                If this is a list of augmenters, it will be converted to a
                :class:`~imgaug.augmenters.meta.Sequential`.


            random_order( boolean, optional):
                Whether to apply the child augmenters in random order.
                If ``True``, the order will be randomly sampled once per batch.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SomeOf(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Sometimes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Sometimes``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.Sometimes>`_ 

            then_list( None or imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) to apply to `p%` percent of all images.
                If this is a list of augmenters, it will be converted to a
                :class:`~imgaug.augmenters.meta.Sequential`.


            else_list( None or imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter, optional):
                Augmenter(s) to apply to ``(1-p)`` percent of all images.
                These augmenters will be applied only when the ones in `then_list`
                are *not* applied (either-or-relationship).
                If this is a list of augmenters, it will be converted to a
                :class:`~imgaug.augmenters.meta.Sequential`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Sometimes(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.StochasticParameterMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``StochasticParameterMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.StochasticParameterMaskGen>`_ 

            parameter( imgaug.parameters.StochasticParameter):
                Stochastic parameter to draw mask samples from.
                Expected to return values in interval ``[0.0, 1.0]`` (not all
                stochastic parameters do that) and must be able to handle sampling
                shapes ``(H, W)`` and ``(H, W, C)`` (all stochastic parameters should
                do that).


            per_channel( bool or float or imgaug.parameters.StochasticParameter, optional):
                Whether to use the same mask for all channels (``False``)
                or to sample a new mask for each channel (``True``).
                If this value is a float ``p``, then for ``p`` percent of all rows
                (i.e. images) `per_channel` will be treated as ``True``, otherwise
                as ``False``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.StochasticParameterMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SubsamplingPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``SubsamplingPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.SubsamplingPointsSampler>`_ 

            other_points_sampler( IPointsSampler):
                Another point sampler that is queried to generate a ``list`` of points.
                The dropout operation will be applied to that ``list``.


            n_points_max( int):
                Maximum number of allowed points. If `other_points_sampler` generates
                more points than this maximum, a random subset of size `n_points_max`
                will be selected.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.SubsamplingPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.TotalDropout:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``TotalDropout``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.TotalDropout>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.TotalDropout(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.TranslateX:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``TranslateX``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.TranslateX>`_ 

            percent( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``translate_percent`` in :class:`Affine`, except that
                this translation value only affects the x-axis. No dictionary input
                is allowed.


            px( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter or dict {"x": int/tuple/list/StochasticParameter, "y": int/tuple/list/StochasticParameter}, optional):
                Analogous to ``translate_px`` in :class:`Affine`, except that
                this translation value only affects the x-axis. No dictionary input
                is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.TranslateX(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.TranslateY:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``TranslateY``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.TranslateY>`_ 

            percent( None or number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Analogous to ``translate_percent`` in :class:`Affine`, except that
                this translation value only affects the y-axis. No dictionary input
                is allowed.


            px( None or int or tuple of int or list of int or imgaug.parameters.StochasticParameter or dict {"x": int/tuple/list/StochasticParameter, "y": int/tuple/list/StochasticParameter}, optional):
                Analogous to ``translate_px`` in :class:`Affine`, except that
                this translation value only affects the y-axis. No dictionary input
                is allowed.


            order( int or iterable of int or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Interpolation order to use. Same meaning as in ``skimage``:


            cval( number or tuple of number or list of number or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                The constant value to use when filling in newly created pixels.
                (E.g. translating by 1px to the right will create a new 1px-wide
                column of pixels on the left of the image).  The value is only used
                when `mode=constant`. The expected value range is ``[0, 255]`` for
                ``uint8`` images. It may be a float value.


            mode( str or list of str or imgaug.ALL or imgaug.parameters.StochasticParameter, optional):
                Method to use when filling in newly created pixels.
                Same meaning as in ``skimage`` (and :func:`numpy.pad`):


            fit_output( bool, optional):
                Whether to modify the affine transformation so that the whole output
                image is always contained in the image plane (``True``) or accept
                parts of the image being outside the image plane (``False``).
                This can be thought of as first applying the affine transformation
                and then applying a second transformation to "zoom in" on the new
                image so that it fits the image plane,
                This is useful to avoid corners of the image being outside of the image
                plane after applying rotations. It will however negate translation
                and scaling.
                Note also that activating this may lead to image sizes differing from
                the input image sizes. To avoid this, wrap ``Affine`` in
                :class:`~imgaug.augmenters.size.KeepSizeByResize`,
                e.g. ``KeepSizeByResize(Affine(...))``.


            backend( str, optional):
                Framework to use as a backend. Valid values are ``auto``, ``skimage``
                (scikit-image's warp) and ``cv2`` (OpenCV's warp).
                If ``auto`` is used, the augmenter will automatically try
                to use ``cv2`` whenever possible (order must be in ``[0, 1, 3]``). It
                will silently fall back to skimage if order/dtype is not supported by
                cv2. cv2 is generally faster than skimage. It also supports RGB cvals,
                while skimage will resort to intensity cvals (i.e. 3x the same value
                as RGB). If ``cv2`` is chosen and order is ``2`` or ``4``, it will
                automatically fall back to order ``3``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.TranslateY(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.UniformColorQuantization:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``UniformColorQuantization``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.UniformColorQuantization>`_ 

            n_colors( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Target number of colors to use in the generated output image.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.UniformColorQuantization(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.UniformColorQuantizationToNBits:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``UniformColorQuantizationToNBits``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.UniformColorQuantizationToNBits>`_ 

            nb_bits( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bits to keep in each image's array component.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.UniformColorQuantizationToNBits(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.UniformPointsSampler:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``UniformPointsSampler``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.UniformPointsSampler>`_ 

            n_points( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of points to sample on each image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.UniformPointsSampler(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.UniformVoronoi:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``UniformVoronoi``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.UniformVoronoi>`_ 

            n_points( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of points to sample on each image.


            p_replace( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Defines for any segment the probability that the pixels within that
                segment are replaced by their average color (otherwise, the pixels
                are not changed).
                Examples:


            max_size( int or None, optional):
                Maximum image size at which the augmentation is performed.
                If the width or height of an image exceeds this value, it will be
                downscaled before the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the process. The final output image has the
                same size as the input image. Note that in case `p_replace` is below
                ``1.0``, the down-/upscaling will affect the not-replaced pixels too.
                Use ``None`` to apply no down-/upscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.UniformVoronoi(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.VerticalLinearGradientMaskGen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``VerticalLinearGradientMaskGen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_blend.html#imgaug.augmenters.blend.VerticalLinearGradientMaskGen>`_ 

            min_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Minimum value that the mask will have up to the start point of the
                linear gradient.
                Note that `min_value` is allowed to be larger than `max_value`,
                in which case the gradient will start at the (higher) `min_value`
                and decrease towards the (lower) `max_value`.


            max_value( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Maximum value that the mask will have at the end of the
                linear gradient.


            start_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Position on the y-axis where the linear gradient starts, given as a
                fraction of the axis size. Interval is ``[0.0, 1.0]``, where ``0.0``
                is at the top of the image.
                If ``end_at < start_at`` the gradient will be inverted.


            end_at( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Position on the x-axis where the linear gradient ends, given as a
                fraction of the axis size. Interval is ``[0.0, 1.0]``, where ``1.0``
                is at the bottom of the image.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.VerticalLinearGradientMaskGen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Voronoi:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Voronoi``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_segmentation.html#imgaug.augmenters.segmentation.Voronoi>`_ 

            points_sampler( IPointsSampler):
                A points sampler which will be queried per image to generate the
                coordinates of the centers of voronoi cells.


            p_replace( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Defines for any segment the probability that the pixels within that
                segment are replaced by their average color (otherwise, the pixels
                are not changed).
                Examples:


            max_size( int or None, optional):
                Maximum image size at which the augmentation is performed.
                If the width or height of an image exceeds this value, it will be
                downscaled before the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the process. The final output image has the
                same size as the input image. Note that in case `p_replace` is below
                ``1.0``, the down-/upscaling will affect the not-replaced pixels too.
                Use ``None`` to apply no down-/upscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Voronoi(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.WithBrightnessChannels:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``WithBrightnessChannels``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.WithBrightnessChannels>`_ 

            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to the brightness channels.
                They receive images with a single channel and have to modify these.


            to_colorspace( imgaug.ALL or str or list of str or imgaug.parameters.StochasticParameter, optional):
                Colorspace in which to extract the brightness-related channels.
                Currently, ``imgaug.augmenters.color.CSPACE_YCrCb``, ``CSPACE_HSV``,
                ``CSPACE_HLS``, ``CSPACE_Lab``, ``CSPACE_Luv``, ``CSPACE_YUV``,
                ``CSPACE_CIE`` are supported.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.WithBrightnessChannels(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.WithChannels:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``WithChannels``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_meta.html#imgaug.augmenters.meta.WithChannels>`_ 

            channels( None or int or list of int, optional):
                Sets the channels to be extracted from each image.
                If ``None``, all channels will be used. Note that this is not
                stochastic - the extracted channels are always the same ones.


            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to images, after the channels
                are extracted.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.WithChannels(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.WithColorspace:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``WithColorspace``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.WithColorspace>`_ 

            to_colorspace( str):
                See :func:`~imgaug.augmenters.color.change_colorspace_`.


            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to converted images.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.WithColorspace(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.WithHueAndSaturation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``WithHueAndSaturation``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.WithHueAndSaturation>`_ 

            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to converted images.
                They receive ``int16`` images with two channels (hue, saturation)
                and have to modify these.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.WithHueAndSaturation(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.WithPolarWarping:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``WithPolarWarping``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_geometric.html#imgaug.augmenters.geometric.WithPolarWarping>`_ 

            children( imgaug.augmenters.meta.Augmenter or list of imgaug.augmenters.meta.Augmenter or None, optional):
                One or more augmenters to apply to images after they were transformed
                to polar representation.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.WithPolarWarping(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EnhanceBrightness:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``EnhanceBrightness``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.EnhanceBrightness>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Brightness of the image. Values below ``1.0`` decrease the brightness,
                leading to a black image around ``0.0``. Values above ``1.0`` increase
                the brightness. Sane values are roughly in ``[0.5, 1.5]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.EnhanceBrightness(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EnhanceColor:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``EnhanceColor``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.EnhanceColor>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Colorfulness of the output image. Values close to ``0.0`` lead
                to grayscale images, values above ``1.0`` increase the strength of
                colors. Sane values are roughly in ``[0.0, 3.0]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.EnhanceColor(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EnhanceContrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``EnhanceContrast``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.EnhanceContrast>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Strength of contrast in the image. Values below ``1.0`` decrease the
                contrast, leading to a gray image around ``0.0``. Values
                above ``1.0`` increase the contrast. Sane values are roughly in
                ``[0.5, 1.5]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.EnhanceContrast(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EnhanceSharpness:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``EnhanceSharpness``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.EnhanceSharpness>`_ 

            factor( number or tuple of number or list of number or imgaug.parameters.StochasticParameter, optional):
                Sharpness of the image. Values below ``1.0`` decrease the sharpness,
                values above ``1.0`` increase it. Sane values are roughly in
                ``[0.0, 2.0]``.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.EnhanceSharpness(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterBlur``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterBlur>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterBlur(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterContour:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterContour``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterContour>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterContour(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterDetail:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterDetail``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterDetail>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterDetail(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterEdgeEnhance:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterEdgeEnhance``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterEdgeEnhance>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterEdgeEnhance(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterEdgeEnhanceMore:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterEdgeEnhanceMore``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterEdgeEnhanceMore>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterEdgeEnhanceMore(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterEmboss:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterEmboss``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterEmboss>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterEmboss(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterFindEdges:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterFindEdges``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterFindEdges>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterFindEdges(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterSharpen:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterSharpen``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterSharpen>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterSharpen(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterSmooth:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterSmooth``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterSmooth>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterSmooth(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FilterSmoothMore:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``FilterSmoothMore``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_pillike.html#imgaug.augmenters.pillike.FilterSmoothMore>`_ 


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FilterSmoothMore(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Posterize:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Reduce the number of bits for each color channel.

    Args:
        library (str):  flag for library. Should be one of:  ``albumentations`` , ``imgaug`` , ``torchvision`` .
								Default: `` albumentations``.
        num_bits ((int, int) or int,
                  or list of ints [r, g, b],
                  or list of ints [[r1, r1], [g1, g2], [b1, b2]]): number of high bits.
            If num_bits is a single value, the range will be [num_bits, num_bits].
            Must be in range [0, 8]. Default: 4.
        p (float): probability of applying the transform. Default: 0.5.

        if library = ``imgaug``:       (see: ``UniformColorQuantizationToNBits``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.UniformColorQuantizationToNBits>`_ 

            nb_bits( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bits to keep in each image's array component.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.


        if library = ``torchvision``:       (see: ``RandomPosterize)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomPosterize>`_ 
    
            bits (int): number of bits to keep for each channel (0-8)
            p (float): probability of the image being color inverted. Default value is 0.5
        


    Targets:
    image

    Image types:
        uint8
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Posterize(p=1, num_bits=4, library="albumentations")
        aug = BA.Posterize(p=1, num_bits=4, library="imgaug")
        aug = BA.Posterize(p=1, num_bits=4, library="torchvision")
        image_auged = aug(image=image)["image"]
                library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``imgaug``:       (see: ``Posterize``)                   `[Check Source] <https://imgaug.readthedocs.io/en/latest/source/api_augmenters_color.html#imgaug.augmenters.color.Posterize>`_ 

            nb_bits( int or tuple of int or list of int or imgaug.parameters.StochasticParameter, optional):
                Number of bits to keep in each image's array component.


            to_colorspace( None or str or list of str or imgaug.parameters.StochasticParameter):
                The colorspace in which to perform the quantization.
                See :func:`~imgaug.augmenters.color.change_colorspace_` for valid values.
                This will be ignored for grayscale input images.


            max_size( None or int, optional):
                Maximum image size at which to perform the augmentation.
                If the width or height of an image exceeds this value, it will be
                downscaled before running the augmentation so that the longest side
                matches `max_size`.
                This is done to speed up the augmentation. The final output image has
                the same size as the input image. Use ``None`` to apply no downscaling.


            interpolation( int or str, optional):
                Interpolation method to use during downscaling when `max_size` is
                exceeded. Valid methods are the same as in
                :func:`~imgaug.imgaug.imresize_single_image`.



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Posterize(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug._EnhanceBase:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA._EnhanceBase(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug._FilterBase:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA._FilterBase(p=1,  library="imgaug")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.DataFrameIterator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``keras``:       (see: ``DataFrameIterator``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DataFrameIterator>`_
    
            dataframe: Pandas dataframe containing the filepaths relative to
                `directory` (or absolute paths if `directory` is None) of the
                images in a string column. It should include other column/s
                depending on the `class_mode`:
                - if `class_mode` is `"categorical"` (default value) it must
                    include the `y_col` column with the class/es of each image.
                    Values in column can be string/list/tuple if a single class
                    or list/tuple if multiple classes.
                - if `class_mode` is `"binary"` or `"sparse"` it must include
                    the given `y_col` column with class values as strings.
                - if `class_mode` is `"raw"` or `"multi_output"` it should contain
                    the columns specified in `y_col`.
                - if `class_mode` is `"input"` or `None` no extra column is needed.
            directory: string, path to the directory to read images from. If `None`,
                data in `x_col` column should be absolute paths.
            image_data_generator: Instance of `ImageDataGenerator` to use for
                random transformations and normalization. If None, no transformations
                and normalizations are made.
            x_col: string, column in `dataframe` that contains the filenames (or
                absolute paths if `directory` is `None`).
            y_col: string or list, column/s in `dataframe` that has the target data.
            weight_col: string, column in `dataframe` that contains the sample
                weights. Default: `None`.
            target_size: tuple of integers, dimensions to resize input images to.
            color_mode: One of `"rgb"`, `"rgba"`, `"grayscale"`.
                Color mode to read images.
            classes: Optional list of strings, classes to use (e.g. `["dogs", "cats"]`).
                If None, all classes in `y_col` will be used.
            class_mode: one of "binary", "categorical", "input", "multi_output",
                "raw", "sparse" or None. Default: "categorical".
                Mode for yielding the targets:
                - `"binary"`: 1D numpy array of binary labels,
                - `"categorical"`: 2D numpy array of one-hot encoded labels.
                    Supports multi-label output.
                - `"input"`: images identical to input images (mainly used to
                    work with autoencoders),
                - `"multi_output"`: list with the values of the different columns,
                - `"raw"`: numpy array of values in `y_col` column(s),
                - `"sparse"`: 1D numpy array of integer labels,
                - `None`, no targets are returned (the generator will only yield
                    batches of image data, which is useful to use in
                    `model.predict_generator()`).
            batch_size: Integer, size of a batch.
            shuffle: Boolean, whether to shuffle the data between epochs.
            seed: Random seed for data shuffling.
            data_format: String, one of `channels_first`, `channels_last`.
            save_to_dir: Optional directory where to save the pictures
                being yielded, in a viewable format. This is useful
                for visualizing the random transformations being
                applied, for debugging purposes.
            save_prefix: String prefix to use for saving sample
                images (if `save_to_dir` is set).
            save_format: Format to use for saving sample images
                (if `save_to_dir` is set).
            subset: Subset of data (`"training"` or `"validation"`) if
                validation_split is set in ImageDataGenerator.
            interpolation: Interpolation method used to resample the image if the
                target size is different from that of the loaded image.
                Supported methods are "nearest", "bilinear", and "bicubic".
                If PIL version 1.1.3 or newer is installed, "lanczos" is also
                supported. If PIL version 3.4.0 or newer is installed, "box" and
                "hamming" are also supported. By default, "nearest" is used.
            dtype: Dtype to use for the generated arrays.
            validate_filenames: Boolean, whether to validate image filenames in
            `x_col`. If `True`, invalid images will be ignored. Disabling this option
            can lead to speed-up in the instantiation of this class. Default: `True`.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.DataFrameIterator(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.DirectoryIterator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``keras``:       (see: ``DirectoryIterator``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/DirectoryIterator>`_
    
            directory: string, path to the directory to read images from.
                Each subdirectory in this directory will be
                considered to contain images from one class,
                or alternatively you could specify class subdirectories
                via the `classes` argument.
            image_data_generator: Instance of `ImageDataGenerator`
                to use for random transformations and normalization.
            target_size: tuple of integers, dimensions to resize input images to.
            color_mode: One of `"rgb"`, `"rgba"`, `"grayscale"`.
                Color mode to read images.
            classes: Optional list of strings, names of subdirectories
                containing images from each class (e.g. `["dogs", "cats"]`).
                It will be computed automatically if not set.
            class_mode: Mode for yielding the targets:
                `"binary"`: binary targets (if there are only two classes),
                `"categorical"`: categorical targets,
                `"sparse"`: integer targets,
                `"input"`: targets are images identical to input images (mainly
                    used to work with autoencoders),
                `None`: no targets get yielded (only input images are yielded).
            batch_size: Integer, size of a batch.
            shuffle: Boolean, whether to shuffle the data between epochs.
                If set to False, sorts the data in alphanumeric order.
            seed: Random seed for data shuffling.
            data_format: String, one of `channels_first`, `channels_last`.
            save_to_dir: Optional directory where to save the pictures
                being yielded, in a viewable format. This is useful
                for visualizing the random transformations being
                applied, for debugging purposes.
            save_prefix: String prefix to use for saving sample
                images (if `save_to_dir` is set).
            save_format: Format to use for saving sample images
                (if `save_to_dir` is set).
            follow_links: boolean,follow symbolic links to subdirectories
            subset: Subset of data (`"training"` or `"validation"`) if
                validation_split is set in ImageDataGenerator.
            interpolation: Interpolation method used to resample the image if the
                target size is different from that of the loaded image.
                Supported methods are "nearest", "bilinear", and "bicubic".
                If PIL version 1.1.3 or newer is installed, "lanczos" is also
                supported. If PIL version 3.4.0 or newer is installed, "box" and
                "hamming" are also supported. By default, "nearest" is used.
            dtype: Dtype to use for generated arrays.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.DirectoryIterator(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ImageDataGenerator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``keras``:       (see: ``ImageDataGenerator``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator>`_
    
            featurewise_center: Boolean.
                Set input mean to 0 over the dataset, feature-wise.
            samplewise_center: Boolean. Set each sample mean to 0.
            featurewise_std_normalization: Boolean.
                Divide inputs by std of the dataset, feature-wise.
            samplewise_std_normalization: Boolean. Divide each input by its std.
            zca_whitening: Boolean. Apply ZCA whitening.
            zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.
            rotation_range: Int. Degree range for random rotations.
            width_shift_range: Float, 1-D array-like or int
                - float: fraction of total width, if < 1, or pixels if >= 1.
                - 1-D array-like: random elements from the array.
                - int: integer number of pixels from interval
                    `(-width_shift_range, +width_shift_range)`
                - With `width_shift_range=2` possible values
                    are integers `[-1, 0, +1]`,
                    same as with `width_shift_range=[-1, 0, +1]`,
                    while with `width_shift_range=1.0` possible values are floats
                    in the interval `[-1.0, +1.0)`.
            height_shift_range: Float, 1-D array-like or int
                - float: fraction of total height, if < 1, or pixels if >= 1.
                - 1-D array-like: random elements from the array.
                - int: integer number of pixels from interval
                    `(-height_shift_range, +height_shift_range)`
                - With `height_shift_range=2` possible values
                    are integers `[-1, 0, +1]`,
                    same as with `height_shift_range=[-1, 0, +1]`,
                    while with `height_shift_range=1.0` possible values are floats
                    in the interval `[-1.0, +1.0)`.
            brightness_range: Tuple or list of two floats. Range for picking
                a brightness shift value from.
            shear_range: Float. Shear Intensity
                (Shear angle in counter-clockwise direction in degrees)
            zoom_range: Float or [lower, upper]. Range for random zoom.
                If a float, `[lower, upper] = [1-zoom_range, 1+zoom_range]`.
            channel_shift_range: Float. Range for random channel shifts.
            fill_mode: One of {"constant", "nearest", "reflect" or "wrap"}.
                Default is 'nearest'.
                Points outside the boundaries of the input are filled
                according to the given mode:
                - 'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)
                - 'nearest':  aaaaaaaa|abcd|dddddddd
                - 'reflect':  abcddcba|abcd|dcbaabcd
                - 'wrap':  abcdabcd|abcd|abcdabcd
            cval: Float or Int.
                Value used for points outside the boundaries
                when `fill_mode = "constant"`.
            horizontal_flip: Boolean. Randomly flip inputs horizontally.
            vertical_flip: Boolean. Randomly flip inputs vertically.
            rescale: rescaling factor. Defaults to None.
                If None or 0, no rescaling is applied,
                otherwise we multiply the data by the value provided
                (after applying all other transformations).
            preprocessing_function: function that will be applied on each input.
                The function will run after the image is resized and augmented.
                The function should take one argument:
                one image (NumPy tensor with rank 3),
                and should output a NumPy tensor with the same shape.
            data_format: Image data format,
                either "channels_first" or "channels_last".
                "channels_last" mode means that the images should have shape
                `(samples, height, width, channels)`,
                "channels_first" mode means that the images should have shape
                `(samples, channels, height, width)`.
                It defaults to the `image_data_format` value found in your
                Keras config file at `~/.keras/keras.json`.
                If you never set it, then it will be "channels_last".
            validation_split: Float. Fraction of images reserved for validation
                (strictly between 0 and 1).
            interpolation_order: int, order to use for
                the spline interpolation. Higher is slower.
            dtype: Dtype to use for the generated arrays.
    
        # Examples
        Example of using `.flow(x, y)`:
    
        ```python
        (x_train, y_train), (x_test, y_test) = cifar10.load_data()
        y_train = np_utils.to_categorical(y_train, num_classes)
        y_test = np_utils.to_categorical(y_test, num_classes)
    
        datagen = ImageDataGenerator(
            featurewise_center=True,
            featurewise_std_normalization=True,
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            horizontal_flip=True)
    
        # compute quantities required for featurewise normalization
        # (std, mean, and principal components if ZCA whitening is applied)
        datagen.fit(x_train)
    
        # fits the model on batches with real-time data augmentation:
        model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                            steps_per_epoch=len(x_train) / 32, epochs=epochs)
    
        # here's a more "manual" example
        for e in range(epochs):
            print('Epoch', e)
            batches = 0
            for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
                model.fit(x_batch, y_batch)
                batches += 1
                if batches >= len(x_train) / 32:
                    # we need to break the loop by hand because
                    # the generator loops indefinitely
                    break
        ```
        Example of using `.flow_from_directory(directory)`:
    
        ```python
        train_datagen = ImageDataGenerator(
                rescale=1./255,
                shear_range=0.2,
                zoom_range=0.2,
                horizontal_flip=True)
    
        test_datagen = ImageDataGenerator(rescale=1./255)
    
        train_generator = train_datagen.flow_from_directory(
                'data/train',
                target_size=(150, 150),
                batch_size=32,
                class_mode='binary')
    
        validation_generator = test_datagen.flow_from_directory(
                'data/validation',
                target_size=(150, 150),
                batch_size=32,
                class_mode='binary')
    
        model.fit_generator(
                train_generator,
                steps_per_epoch=2000,
                epochs=50,
                validation_data=validation_generator,
                validation_steps=800)
        ```
    
        Example of transforming images and masks together.
    
        ```python
        # we create two instances with the same arguments
        data_gen_args = dict(featurewise_center=True,
                             featurewise_std_normalization=True,
                             rotation_range=90,
                             width_shift_range=0.1,
                             height_shift_range=0.1,
                             zoom_range=0.2)
        image_datagen = ImageDataGenerator(**data_gen_args)
        mask_datagen = ImageDataGenerator(**data_gen_args)
    
        # Provide the same seed and keyword arguments to the fit and flow methods
        seed = 1
        image_datagen.fit(images, augment=True, seed=seed)
        mask_datagen.fit(masks, augment=True, seed=seed)
    
        image_generator = image_datagen.flow_from_directory(
            'data/images',
            class_mode=None,
            seed=seed)
    
        mask_generator = mask_datagen.flow_from_directory(
            'data/masks',
            class_mode=None,
            seed=seed)
    
        # combine generators into one which yields image and masks
        train_generator = zip(image_generator, mask_generator)
    
        model.fit_generator(
            train_generator,
            steps_per_epoch=2000,
            epochs=50)
        ```
    
        Example of using ```.flow_from_dataframe(dataframe, directory,
                                                x_col, y_col)```:
    
        ```python
    
        train_df = pandas.read_csv("./train.csv")
        valid_df = pandas.read_csv("./valid.csv")
    
        train_datagen = ImageDataGenerator(
                rescale=1./255,
                shear_range=0.2,
                zoom_range=0.2,
                horizontal_flip=True)
    
        test_datagen = ImageDataGenerator(rescale=1./255)
    
        train_generator = train_datagen.flow_from_dataframe(
                dataframe=train_df,
                directory='data/train',
                x_col="filename",
                y_col="class",
                target_size=(150, 150),
                batch_size=32,
                class_mode='binary')
    
        validation_generator = test_datagen.flow_from_dataframe(
                dataframe=valid_df,
                directory='data/validation',
                x_col="filename",
                y_col="class",
                target_size=(150, 150),
                batch_size=32,
                class_mode='binary')
    
        model.fit_generator(
                train_generator,
                steps_per_epoch=2000,
                epochs=50,
                validation_data=validation_generator,
                validation_steps=800)
        ```
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ImageDataGenerator(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Iterator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``keras``:       (see: ``Iterator``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/Iterator>`_
    
            n: Integer, total number of samples in the dataset to loop over.
            batch_size: Integer, size of a batch.
            shuffle: Boolean, whether to shuffle the data between epochs.
            seed: Random seeding for data shuffling.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Iterator(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.NumpyArrayIterator:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	    if library = ``keras``:       (see: ``NumpyArrayIterator``)            `[Check Source] <https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/NumpyArrayIterator>`_
    
            x: Numpy array of input data or tuple.
                If tuple, the second elements is either
                another numpy array or a list of numpy arrays,
                each of which gets passed
                through as an output without any modifications.
            y: Numpy array of targets data.
            image_data_generator: Instance of `ImageDataGenerator`
                to use for random transformations and normalization.
            batch_size: Integer, size of a batch.
            shuffle: Boolean, whether to shuffle the data between epochs.
            sample_weight: Numpy array of sample weights.
            seed: Random seed for data shuffling.
            data_format: String, one of `channels_first`, `channels_last`.
            save_to_dir: Optional directory where to save the pictures
                being yielded, in a viewable format. This is useful
                for visualizing the random transformations being
                applied, for debugging purposes.
            save_prefix: String prefix to use for saving sample
                images (if `save_to_dir` is set).
            save_format: Format to use for saving sample images
                (if `save_to_dir` is set).
            subset: Subset of data (`"training"` or `"validation"`) if
                validation_split is set in ImageDataGenerator.
            dtype: Dtype to use for the generated arrays.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.NumpyArrayIterator(p=1,  library="keras")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AutoAugment:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``AutoAugment)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#AutoAugment>`_ 
    
            policy (AutoAugmentPolicy): Desired policy enum defined by
                :class:`torchvision.transforms.autoaugment.AutoAugmentPolicy`. Default is ``AutoAugmentPolicy.IMAGENET``.
            interpolation (InterpolationMode): Desired interpolation enum defined by
                :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.NEAREST``.
                If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
            fill (sequence or number, optional): Pixel fill value for the area outside the transformed
                image. If given a number, the value is used for all bands respectively.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AutoAugment(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.AutoAugmentPolicy:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``AutoAugmentPolicy)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#AutoAugmentPolicy>`_ 
		AutoAugment policies learned on different datasets.
    Available policies are IMAGENET, CIFAR10 and SVHN.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.AutoAugmentPolicy(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ConvertImageDtype:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``ConvertImageDtype)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#ConvertImageDtype>`_ 
    
            dtype (torch.dtype): Desired data type of the output


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ConvertImageDtype(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.FiveCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``FiveCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#FiveCrop>`_ 
    
             size (sequence or int): Desired output size of the crop. If size is an ``int``
                instead of sequence like (h, w), a square crop of size (size, size) is made.
                If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.FiveCrop(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.LinearTransformation:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``LinearTransformation)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#LinearTransformation>`_ 
    
            transformation_matrix (Tensor): tensor [D x D], D = C x H x W
            mean_vector (Tensor): tensor [D], D = C x H x W
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.LinearTransformation(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PILToTensor:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``PILToTensor)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#PILToTensor>`_ 
		Convert a ``PIL Image`` to a tensor of the same type. This transform does not support torchscript.

    Converts a PIL Image (H x W x C) to a Tensor of shape (C x H x W).
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.PILToTensor(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomAdjustSharpness:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomAdjustSharpness)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomAdjustSharpness>`_ 
    
            sharpness_factor (float):  How much to adjust the sharpness. Can be
                any non negative number. 0 gives a blurred image, 1 gives the
                original image while 2 increases the sharpness by a factor of 2.
            p (float): probability of the image being color inverted. Default value is 0.5
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomAdjustSharpness(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomApply:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomApply)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomApply>`_ 
    
            transforms (sequence or torch.nn.Module): list of transformations
            p (float): probability
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomApply(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomAutocontrast:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomAutocontrast)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomAutocontrast>`_ 
    
            p (float): probability of the image being autocontrasted. Default value is 0.5
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomAutocontrast(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomChoice:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomChoice)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomChoice>`_ 
		Apply single transformation randomly picked from a list. This transform does not support torchscript.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomChoice(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomOrder:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomOrder)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomOrder>`_ 
		Apply a list of transformations in a random order. This transform does not support torchscript.
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomOrder(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomPerspective:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``RandomPerspective)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#RandomPerspective>`_ 
    
            distortion_scale (float): argument to control the degree of distortion and ranges from 0 to 1.
                Default is 0.5.
            p (float): probability of the image being transformed. Default is 0.5.
            interpolation (InterpolationMode): Desired interpolation enum defined by
                :class:`torchvision.transforms.InterpolationMode`. Default is ``InterpolationMode.BILINEAR``.
                If input is Tensor, only ``InterpolationMode.NEAREST``, ``InterpolationMode.BILINEAR`` are supported.
                For backward compatibility integer values (e.g. ``PIL.Image.NEAREST``) are still acceptable.
            fill (sequence or number): Pixel fill value for the area outside the transformed
                image. Default is ``0``. If given a number, the value is used for all bands respectively.
        



    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.RandomPerspective(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.TenCrop:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``TenCrop)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#TenCrop>`_ 
    
            size (sequence or int): Desired output size of the crop. If size is an
                int instead of sequence like (h, w), a square crop (size, size) is
                made. If provided a sequence of length 1, it will be interpreted as (size[0], size[0]).
            vertical_flip (bool): Use vertical flipping instead of horizontal


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.TenCrop(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ToPILImage:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``ToPILImage)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#ToPILImage>`_ 
    
            mode (`PIL.Image mode`_): color space and pixel depth of input data (optional).
                If ``mode`` is ``None`` (default) there are some assumptions made about the input data:
                - If the input has 4 channels, the ``mode`` is assumed to be ``RGBA``.
                - If the input has 3 channels, the ``mode`` is assumed to be ``RGB``.
                - If the input has 2 channels, the ``mode`` is assumed to be ``LA``.
                - If the input has 1 channel, the ``mode`` is determined by the data type (i.e ``int``, ``float``,
                ``short``).


    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ToPILImage(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ToTensor:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``ToTensor)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#ToTensor>`_ 
		Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor. This transform does not support torchscript.

    Converts a PIL Image or numpy.ndarray (H x W x C) in the range
    [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]
    if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1)
    or if the numpy.ndarray has dtype = np.uint8

    In the other cases, tensors are returned without scaling.

    .. note::
        Because the input image is scaled to [0.0, 1.0], this transformation should not be used when
        transforming target image masks. See the `references`_ for implementing the transforms for image masks.

    .. _references: https://github.com/pytorch/vision/tree/master/references/segmentation
    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.ToTensor(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Enum:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	        if library = ``torchvision``:       (see: ``Enum)``        )  `[Check Source] <https://pytorch.org/vision/stable/_modules/torchvision/transforms/transforms.html#Enum>`_ 
		Generic enumeration.

    Derive from this class to define new enumerations.

    
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Enum(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Tensor:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        aug = BA.Tensor(p=1,  library="torchvision")
        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ChangeAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ConvertColor:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.EncodingQuality:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MaskedComposite:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.MemeFormat:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Opacity:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OverlayEmoji:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OverlayImage:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OverlayOntoScreenshot:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.OverlayStripes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.PadSquare:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomAspectRatio:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomEmojiOverlay:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.RandomNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ShufflePixels:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.DefocusBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.ZoomBlur:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Frost:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.SpeckleNoise:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        

----

beacon_aug.Spatter:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

        library(str): flag for library. Should be one of: `` albumentations``, `` imgaug``, `` torchvision``.     Default: `` albumentations``     Args:
	
    e.g.

    .. code-block::

        import beacon_aug as BA

        image_auged = aug(image=image)["image"]
        